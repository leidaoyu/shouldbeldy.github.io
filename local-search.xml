<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>文本分类任务基本流程</title>
    <link href="/2023/04/25/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B/"/>
    <url>/2023/04/25/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="文本分类任务基本流程"><a href="#文本分类任务基本流程" class="headerlink" title="文本分类任务基本流程"></a>文本分类任务基本流程</h1><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><strong>文本来源于笔者在openmmlab工程团队的知识分享。</strong></p><p>文本分类是自然语言处理领域的一项基本任务，它涉及将给定文本分配到一个或多个预定义的类别，根据输出的不同分为单标签多分类(一个句子对应一个标签，如某一个新闻文本属于经济新闻或娱乐新闻等)和多标签分类(一个句子对应多个标签，比如一个新闻文本既属于经济新闻又属于娱乐新闻)。本文将以单标签多分类任务为例，简单介绍一下用pytorch实现BERT中文文本分类的基本流程。</p><h1 id="任务流程"><a href="#任务流程" class="headerlink" title="任务流程"></a>任务流程</h1><p><img src="https://s3.bmp.ovh/imgs/2023/04/25/91b39c1f2e9c00c0.png" alt="文本分类流程"></p><p>文本分类的基本流程一般是<code>文本-&gt;文本预处理-&gt;特征抽取-&gt;分类器训练-&gt;分类器评估-&gt;预测</code>。首先需要将文本进行清洗处理成结构化的数据，比如每一条文本处理成<code>sentence+&#39;\t&#39;+label</code>的形式，然后采用不同的word embedding方法将文本转换成向量，然后构建分类模型，将文本向量输入模型进行训练，每一个epoch后进行evaluation验证，最后进行预测。</p><h1 id="流程相关概念介绍"><a href="#流程相关概念介绍" class="headerlink" title="流程相关概念介绍"></a>流程相关概念介绍</h1><h2 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h2><p>在CV任务中，输入往往是图像，对于一个图像而言，图像本身就是由像素点矩阵构成的，RGB通道的图像更是三维的矩阵，本身就含有大量的特征信息，而且能被计算机直接理解。而NLP任务的输入是句子，计算机无法直接理解句子，所以所有nlp任务的第一步也是相当重要的一步就是将单词或者句子转化成向量，这个过程称为<code>词嵌入(word embedding)</code>。</p><p>简单来说每一个nlp模型都需要一个词表，通过词表先将一句话转化成一个编号向量，对于中文nlp任务还涉及到一个粒度的问题，有的模型是词粒度(每一个词转化成一个编号)，有的模型是字粒度(每一个字作为一个编号)，词表的每一个元素称为一个token。</p><p><img src="https://s3.bmp.ovh/imgs/2023/04/25/2e7c9e453c21e6a8.png" alt="str2index"></p><p>如图，根据不同的处理规则和词表，可以将句子转化成词表对应的下标向量(如果出现不存在的token一般会用一个<code>UKN(unknown)</code>token来表示)，将句子转化成下标向量后，下一步是采用不同的特征提取方式将每一个token转化成一个向量，这样就可以达到将计算机无法理解的句子转化成计算机可以理解的向量的效果。根据词嵌入的原理大致可以细分成以下几种方法，具体方法原理可以查看对应的链接。</p><iframe src="https://leidaoyu.github.io/webpage/markmap.html" width="100%" height="500" frameborder="0" allowfullscreen></iframe><p>静态词嵌入是指，每一个token对应的向量是固定的，静态词向量的维度一般设置在300，即每一个token会被转变成一个300维的固定的词向量；动态词嵌入会根据词语所在的句子，通过BERT等预训练模型动态的生成词向量，比如“苹果公司推出了新产品”和“我今天吃了一个苹果”两个句子中的“苹果”通过动态词嵌入生成的向量是不一样的。动态词向量更能够学习到文本的上下文语义，极大的提升了nlp任务的效果。</p><h2 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h2><p>预训练模型是一种深度学习模型，这种模型首先在大规模数据集上进行了预先训练，以学习文本或图像通用的特征或表示，然后在各种下游任务中进行微调，以适应特定的任务需求，从而极大地减少了训练时间和所需的数据量。</p><h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><h3 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h3><p><img src="https://s3.bmp.ovh/imgs/2023/04/25/b2805dbce9847463.png" alt="confusion matrix"></p><p>混淆矩阵也称误差矩阵，是表示精度评价的一种标准格式，用n行n列的矩阵形式来表示。混淆矩阵（confusion matrix）是可视化工具，混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。</p><h3 id="准确率Acc"><a href="#准确率Acc" class="headerlink" title="准确率Acc"></a>准确率Acc</h3><p>准确率Accuracy就是所有预测正确的所有样本除以总样本，通常来说越接近1越好。准确率的使用有一定的局限性。比如当样本不平衡时，假设有99个负例，一个正例。如果模型将这些样本全部预测成了负例，准确率为99%，这显然是不合理的，此时准确率就失去了衡量模型性能的作用。在这种情况下，可以使用查准率和查全率，这两个指标对长尾数据集的模型评价更有说服力。</p><p>在上图总共100个样本，我们一共预测对了15 + 15 + 45&#x3D;75个样本，所以准确率&#x3D;75&#x2F;100 &#x3D; 75%。</p><h3 id="查准率Precision"><a href="#查准率Precision" class="headerlink" title="查准率Precision"></a>查准率Precision</h3><p>精确率是正确分类为正类的样本数占所有被预测为正类的样本数的比例，精确率关注的是模型预测类别的准确性。</p><p>上图中对于A来说，共有24个样本被预测成A，但是其中只有15个样本真实是A，所以A的查准率&#x3D;15&#x2F;24&#x3D;62.5%</p><h3 id="查全率Recall"><a href="#查全率Recall" class="headerlink" title="查全率Recall"></a>查全率Recall</h3><p>查全率是正确分类为正类的样本数占所有实际为正类的样本数的比例，查全率关注的是模型识别类别的能力。</p><p>上图中对于A来说，共有20个样本A，但是其中只有15个样本被模型识别成了A，所以A的查全率&#x3D;15&#x2F;20&#x3D;62.5%</p><h3 id="F1分数F1-score"><a href="#F1分数F1-score" class="headerlink" title="F1分数F1-score"></a>F1分数F1-score</h3><p>F1分数是精确率和召回率的调和平均值，用于综合考虑精确率和召回率。当我们想要在精确率和召回率之间取得平衡时，F1分数是一个很好的指标。F1的计算公式为</p><p><img src="https://s3.bmp.ovh/imgs/2023/04/25/2695a805b2d402a2.png" alt="F1"></p><h2 id="常见超参数及模型相关概念"><a href="#常见超参数及模型相关概念" class="headerlink" title="常见超参数及模型相关概念"></a>常见超参数及模型相关概念</h2><ul><li>device：在模型训练中，输入数据和模型放置的设备(cpu&#x2F;gpu)</li><li>batch_size：在模型训练中，由于显存限制的原因，往往不能把全量的数据输入模型进行训练，所以需要把数据切分成更小的bacth，以batch为单位输入模型进行训练，batch_size指每一个batch包含多少条数据</li><li>pad_size：在NLP任务中，我们通常需要处理的是不同长度的文本数据，为了使输入数据能够在神经网络中进行并行计算，我们需要将所有序列统一成相同的长度。pad_size就是设定一个固定的长度，对于长度较小的文本后面添加特殊token（通常是<code>[PAD]</code>），对于长度较大的文本直接截断，从而实现长度的统一。</li><li>epoch：轮次，每次把所有batch都输入到模型训练一次即为一次epoch。</li><li><a href="https://blog.csdn.net/weixin_38346042/article/details/128481422">weight_decay</a>：权重衰减，通过在Loss函数后加一个正则化项，通过使权重减小的方式，一定减少模型过拟合的问题。</li><li><a href="https://zhuanlan.zhihu.com/p/56029557">learning_rate</a>：学习率，控制我们要多大程度调整网络的权重，以符合梯度损失，值越低沿着梯度下降越慢，越高下降越快。</li><li>bert_lr_ratio：由于bert等预训练模型的拟合能力过强，所以一般而言非bert层的学习率需要是bert层的5-10倍，bert_lr_ratio用来控制bert层学习率的百分比，一般设置为0.2。</li><li>patience：为了防止模型过拟合和资源浪费，如果模型训练过程中，持续patience个epoch，模型的效果还没有提升，我们就认为此时模型已经拟合，就会提前停止。</li><li><a href="https://zhuanlan.zhihu.com/p/38200980">dropout</a>：dropout是指在神经网络的训练过程中随机地将某些神经元的输出设置为0。这样做的目的是为了防止过拟合，即模型过于依赖训练数据，无法泛化到新的数据上。通过随机地丢弃一部分神经元，dropout可以减少神经网络中神经元之间的复杂关系，从而提高模型的鲁棒性和泛化能力。在测试时，不再对神经元进行随机丢弃，而是将所有神经元都保留下来。</li><li>mask：因为我们会对文本做PAD处理，对于模型而言<code>[PAD]</code>是没有意义的，所以需要知道encode后的token哪些是真实文本，哪些是<code>[PAD]</code>，我们会用一组0&#x2F;1向量来标识非<code>[PAD]</code>token，这个向量称为mask向量</li><li>Special mark:在预训练模型中，有一些特殊的token用来表示特殊的意思，常见的包括：<ul><li><code>[PAD]</code>:表示填充的token。</li><li><code>[CLS]</code>:放在每一个句子的首位，表示句子级别的特征。</li><li><code>[SEP]</code>:放在句子的尾位，表示一个句子结束。在句子对任务学习中用来区分不同的句子。</li><li><code>[UNK]</code>:表示词表里没有的token。</li></ul></li><li><a href="https://zhuanlan.zhihu.com/p/261695487">optimizer</a>：优化器就是在深度学习反向传播过程中，指引损失函数（目标函数）的各个参数往正确的方向更新合适的大小，使得更新后的各个参数让损失函数（目标函数）值不断逼近全局最小。简单来说就是让loss变成最小的算法。</li></ul><h1 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h1><h2 id="超参数的设置"><a href="#超参数的设置" class="headerlink" title="超参数的设置"></a>超参数的设置</h2><p>首先需要设置模型训练<a href="https://www.notion.so/a4a02d8de29d469ca74ea3af34deece0">相关的超参数</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 各项参数设置</span><br>dataset = <span class="hljs-string">&#x27;data/THUCnews&#x27;</span><br>labels_name = [w.strip() <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(os.path.join(dataset, <span class="hljs-string">&#x27;class.txt&#x27;</span>), <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf8&#x27;</span>).readlines()]<br>pad_size = <span class="hljs-number">32</span><br>device = torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>)  <span class="hljs-comment"># cpu</span><br><span class="hljs-comment"># device = torch.device(&#x27;cuda&#x27;)  # 设备gpu</span><br>batch_size = <span class="hljs-number">4</span><br>bert_path = <span class="hljs-string">&#x27;bert-base-chinese&#x27;</span><br>num_classes = <span class="hljs-built_in">len</span>(labels_name)<br>weight_decay = <span class="hljs-number">0.02</span><br>num_epochs = <span class="hljs-number">30</span><br>learning_rate = <span class="hljs-number">5e-5</span><br>bert_lr_ratio = <span class="hljs-number">0.2</span><br>dropout = <span class="hljs-number">0.1</span><br>patience = <span class="hljs-number">6</span><br>save_path = <span class="hljs-string">&#x27;saved_dict/bert.ckpt&#x27;</span> <span class="hljs-comment"># 模型保存地址</span><br><br></code></pre></td></tr></table></figure><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>根据原始数据集采用适当的办法将数据集处理成文本和标签一一对应的格式，便于后续的数据读取。只要处理成一一对应的形式即可，比如将每一条文本和标签用<code>\t</code>拼接，后续可以很方便的处理。</p><p><img src="https://s3.bmp.ovh/imgs/2023/04/25/7bf285f4e60415da.png" alt="data process"></p><h2 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h2><p>首先读取数据，将文本和对应的label对应起来。本文是用一个用一个二维的tuple保存单条数据，然后存到list中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-comment"># 读取数据集</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_loader</span>(<span class="hljs-params">file_path</span>):<br>    contents = []<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(file_path, <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;UTF-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> tqdm(f):<br>            lin = line.strip()<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> lin:<br>                <span class="hljs-keyword">continue</span><br>            content, label = lin.split(<span class="hljs-string">&#x27;\t&#x27;</span>)<br>            contents.append((content, label))<br>    <span class="hljs-keyword">return</span> contents<br><br>train_data = data_loader(os.path.join(dataset, <span class="hljs-string">&#x27;train.txt&#x27;</span>))<br>dev_data = data_loader(os.path.join(dataset, <span class="hljs-string">&#x27;dev.txt&#x27;</span>))<br>test_data = data_loader(os.path.join(dataset, <span class="hljs-string">&#x27;test.txt&#x27;</span>))<br><br><span class="hljs-built_in">print</span>(test_data[:<span class="hljs-number">5</span>])<br><span class="hljs-built_in">print</span>(labels_name)<br><br></code></pre></td></tr></table></figure><p><img src="https://s3.bmp.ovh/imgs/2023/04/25/41095902c1c2ede2.png" alt="data detail"></p><h2 id="数据编码"><a href="#数据编码" class="headerlink" title="数据编码"></a>数据编码</h2><p>读取数据后，需要对数据进行encode，nlp里的预训练模型在使用上可以粗暴地理解简单粗暴地认为通常包含两部分，一个是tokenizer，用来将句子转化为一个一个token，另一部分就是预训练模型本身，可以将每一个token特征提取成一个n维的向量，比如bert类预训练模型一般转化后的向量是768维。</p><p>下图中调用了transformers包的BertTokenizer方法，加载bert预训练的tokenizer后对数据进行编码，下图中的各项参数含义如下：</p><ul><li><code>text</code>：要编码的文本，字符串类型。</li><li><code>max_length</code>：编码后的序列的最大长度。如果输入文本长度超过了 <code>max_length</code>，则根据 <code>truncation_strategy</code> 参数截断或填充到指定长度。默认为 <code>None</code>，表示不限制序列长度。</li><li><code>truncation</code>：一个布尔值，表示是否截断输入文本以适合指定的序列长度。如果为 <code>True</code>，则输入文本长度超过 <code>max_length</code> 时将被截断。如果为 <code>False</code>，则不进行截断操作。默认为 <code>True</code>。</li><li><code>truncation_strategy</code>：一个字符串，表示截断策略。有两个可选值：“longest_first” 和 “only_first”。如果选择 “longest_first”，则将文本截断为长度等于 <code>max_length</code> 的最长子串；如果选择 “only_first”，则将文本截断为开头的长度等于 <code>max_length</code> 的子串。默认为 “longest_first”。</li><li><code>add_special_tokens</code>：一个布尔值，表示是否在序列的开头和结尾添加特殊的标记，如 <code>[CLS]</code> 和 <code>[SEP]</code>。默认为 <code>True</code>。</li><li><code>pad_to_max_length</code>：一个布尔值，表示是否填充序列以达到指定的 <code>max_length</code>。如果为 <code>True</code>，则在序列末尾添加特殊的填充标记，使序列长度达到 <code>max_length</code>。如果为 <code>False</code>，则不进行填充操作。默认为 <code>True</code>。</li></ul><p>对于经过pad后的句子，我们还需要构造一个mask向量用来标识哪些token是pad，这样每一条数据就会变成一个三维tuple（tokenizer后的句子向量，mask句子向量，标签label）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertModel<br><span class="hljs-comment"># 数据encode</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode_data</span>(<span class="hljs-params">tokenizer, data</span>):<br>    data_encoded = []<br>    <span class="hljs-keyword">for</span> text, label <span class="hljs-keyword">in</span> tqdm(data, total=<span class="hljs-built_in">len</span>(data)):<br>        inputs = tokenizer.encode(text=text, max_length=pad_size, truncation=<span class="hljs-literal">True</span>,<br>                                  truncation_strategy=<span class="hljs-string">&#x27;longest_first&#x27;</span>,<br>                                  add_special_tokens=<span class="hljs-literal">True</span>, pad_to_max_length=<span class="hljs-literal">True</span>)<br>        data_encoded.append((inputs, [<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> x != <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> inputs], <span class="hljs-built_in">int</span>(label)))<br>    <span class="hljs-keyword">return</span> data_encoded<br><br>tokenizer = BertTokenizer.from_pretrained(bert_path)<br><br>train_data = encode_data(tokenizer, train_data)<br>dev_data = encode_data(tokenizer, dev_data)<br>test_data = encode_data(tokenizer, test_data)<br><br><span class="hljs-built_in">print</span>(train_data[<span class="hljs-number">0</span>])<br><br></code></pre></td></tr></table></figure><p><img src="https://s3.bmp.ovh/imgs/2023/04/25/bb1807cd93b7d893.png" alt="encode"></p><p>随后我们需要进行输入的包装，一方面是将刚才生成的向量转化为张量Tensor，然后放到设置的device上进行模型训练（矩阵运算），另一方面是将数据切分成一个个batch。常见的工具类有<code>torch.utils.data</code>下的 <code>TensorDataset</code>  <code>DataLoader</code>。这两个方法往往是组合起来使用，<code>TensorDataset</code>用来整理数据，<code>DataLoader</code>用来切分和读取数据。</p><p>具体来说下图中的<code>zip(*train_data)])</code>的作用是将之前的tuple list按列展开重新组合，之前的数据格式是<code>[(input_id, mask, label),...]</code>现在就会变成<code>[(input_id1,input_id2,...),(mask1,mask2,...),(label1,label2,...)]</code>然后遍历每一个元素，将元素转化成张量后放到device上；然后用<code>DataLoader</code>将其包装成迭代器，下图中的各参数含义如下：</p><ul><li><code>dataset</code>: 数据集对象，通常是 <code>TensorDataset</code> 类的实例。</li><li><code>batch_size</code>: 每个批次的数据量大小。</li><li><code>shuffle</code>: 是否在每个epoch之前对数据进行随机打乱。</li><li><code>drop_last</code>: 是否将最后一个不足一个批次大小的数据扔掉。</li></ul><p>我们可以发现每一个句子经过tokenizer后都会变成101开头和102结尾，句子pad部分都会变成0，这三个下标其实就是对应bert预训练模型词表中的<code>[CLS]、[SEP]</code>和<code>[PAD]</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> TensorDataset, DataLoader<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-comment"># 迭代器包装</span><br>train_dataset = TensorDataset(*[torch.LongTensor(x).to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(*train_data)])<br>dev_dataset = TensorDataset(*[torch.LongTensor(x).to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(*dev_data)])<br>test_dataset = TensorDataset(*[torch.LongTensor(x).to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(*test_data)])<br>train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">False</span>)<br>dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">False</span>)<br>test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>, drop_last=<span class="hljs-literal">False</span>)<br>test_iter = <span class="hljs-built_in">iter</span>(test_loader)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">next</span>(test_iter))<br></code></pre></td></tr></table></figure><p><img src="https://s3.bmp.ovh/imgs/2023/04/25/7afe3c8fd93ecd09.png" alt="data loader"></p><h2 id="网络搭建"><a href="#网络搭建" class="headerlink" title="网络搭建"></a>网络搭建</h2><p>数据处理部分结束后，我们需要搭建网络，如果不关心模型内部的运算过程，实际上我们在使用深度学习网络的时候只需要知道每一个网络的输入输出是什么shape(形状)，shape的每一个维度代表什么含义即可。</p><p>如图，对于下面这个示例句子，经过encode之后输入bert预训练模型，输出由两部分，第一部分包含这个句子每一个token的特征张量，第二部分是句子的<code>[[CLS]token](https://aicarrier.feishu.cn/docx/DcIYd0xjIoS7k1x9GcwcdScJnlC#part-UYw0drPzNokAPJxjdJbcVBoJnWd)</code>的特征。对于句子级别的文本分类，我们只需要关注<code>[CLS]</code>token即可，经过bert模型后句子会变成<code>[sample_number,768]</code>的形状，然后通过一个全连接层将768维压缩到需要分类的类别（图中是5），这样句子最终会变成<code>[sample_number,label_number]</code>的形状，此时第二维可以看做句子属于不同类别的概率，取概率最高的label作为预测结果即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertModel<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 用预训练的BERT模型进行初始化</span><br>tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&#x27;bert-base-chinese&#x27;</span>)<br>model = BertModel.from_pretrained(<span class="hljs-string">&#x27;bert-base-chinese&#x27;</span>)<br><span class="hljs-comment"># 输入句子</span><br>sentence = <span class="hljs-string">&quot;这是一个示例句子。&quot;</span><br><span class="hljs-comment"># 使用BERT Tokenizer对句子进行编码</span><br>input_ids = tokenizer.encode(text=sentence)<br>input_ids = torch.LongTensor(input_ids).unsqueeze(<span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># 使用BERT模型获取词嵌入</span><br><span class="hljs-keyword">with</span> torch.no_grad():<br>    last_hidden_states,cls_states = model(input_ids, return_dict=<span class="hljs-literal">False</span>)<br>lc = nn.Linear(<span class="hljs-number">768</span>, <span class="hljs-number">5</span>)<br>out = lc(cls_states)<br><br><span class="hljs-comment"># print(last_hidden_states)</span><br><span class="hljs-built_in">print</span>(input_ids) <span class="hljs-comment"># tokenizer后的句子张量</span><br><span class="hljs-built_in">print</span>(last_hidden_states.shape) <span class="hljs-comment"># bert输出的句子embedding张量，shape第一维表示句子，第二维表示token，第三维表示token的特征维度</span><br><span class="hljs-built_in">print</span>(cls_states.shape) <span class="hljs-comment"># bert输出的[CLS]的张量，shape第一维表示句子，第二维表示特征维度</span><br><span class="hljs-built_in">print</span>(out.shape) <span class="hljs-comment"># [CLS]张量经过全连接层后的输出，输出每一个label的概率</span><br></code></pre></td></tr></table></figure><p><img src="https://s3.bmp.ovh/imgs/2023/04/25/58d95edf7ff3a267.png" alt="model demo"></p><p>回到本文，基于bert的文本分类网络搭建实际上也只需要两层即可，第一层bert层做特征抽取，第二层linear层做label输出，整体网络结构图如下。<code>__init__</code>部分是网络初始化各个层，<code>forward</code>部分是网络进行计算的流程。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-comment"># 模型网络搭建</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, bert_path, hidden_size, num_classes</span>):<br>        <span class="hljs-built_in">super</span>(Model, self).__init__()<br>        self.bert = BertModel.from_pretrained(bert_path) <span class="hljs-comment"># 加载预训练模型</span><br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.bert.parameters():<br>            param.requires_grad = <span class="hljs-literal">True</span> <span class="hljs-comment"># 在训练中更新bert预训练模型的权重</span><br>        self.fc = nn.Linear(hidden_size, num_classes) <span class="hljs-comment"># 全连接层分类</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        context = x[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 输入的句子</span><br>        mask = x[<span class="hljs-number">1</span>]  <span class="hljs-comment"># 对padding部分进行mask，和句子一个size，padding部分用0表示，如：[1, 1, 1, 1, 0, 0]</span><br>        _, pooled = self.bert(context, attention_mask=mask, return_dict=<span class="hljs-literal">False</span>)<br>        out = self.fc(pooled)<br>        <span class="hljs-keyword">return</span> out<br><br><span class="hljs-comment"># 初始化模型</span><br>model = Model(bert_path, <span class="hljs-number">768</span>, num_classes).to(device)<br><span class="hljs-built_in">print</span>(model.parameters)<br><br></code></pre></td></tr></table></figure><h2 id="优化器设置"><a href="#优化器设置" class="headerlink" title="优化器设置"></a>优化器设置</h2><p>在模型开始前还需要初始化优化器，优化器简单来讲就是让模型训练的过程中loss尽可能的逼近全局最小的算法，目前一般用AdamW优化器比较多。下面代码是对于使用了bert类型预训练模型的优化器设置，一般来讲是固定的，他的作用是把<a href="https://www.notion.so/a4a02d8de29d469ca74ea3af34deece0">bert层的学习率设置的低一点</a>，然后对于有权重衰减层设置权重衰减，没有权重衰减层设置权重衰减为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_optimizer</span>(<span class="hljs-params">model</span>):<br>    param_optimizer = <span class="hljs-built_in">list</span>(model.named_parameters())<br>    no_decay = [<span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-string">&#x27;LayerNorm.bias&#x27;</span>, <span class="hljs-string">&#x27;LayerNorm.weight&#x27;</span>]<br>    bert_param_ids = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">id</span>, param_optimizer))<br>    no_weight_decay_params = [x[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">filter</span>(<br>        <span class="hljs-keyword">lambda</span> name_w: <span class="hljs-built_in">any</span>(nwd <span class="hljs-keyword">in</span> name_w[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> nwd <span class="hljs-keyword">in</span> no_decay), model.named_parameters())]<br>    no_weight_decay_param_ids = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">id</span>, [x[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> no_weight_decay_params]))<br>    bert_base_params = <span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">in</span> bert_param_ids <span class="hljs-keyword">and</span> <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> no_weight_decay_param_ids,<br>                              model.parameters())<br>    bert_no_weight_decay_params = <span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">in</span> bert_param_ids <span class="hljs-keyword">and</span> <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">in</span> no_weight_decay_param_ids,<br>                                         model.parameters())<br>    base_no_weight_decay_params = <span class="hljs-built_in">filter</span>(<br>        <span class="hljs-keyword">lambda</span> p: <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> bert_param_ids <span class="hljs-keyword">and</span> <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">in</span> no_weight_decay_param_ids,<br>        model.parameters())<br>    base_params = <span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> bert_param_ids <span class="hljs-keyword">and</span> <span class="hljs-built_in">id</span>(p) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> no_weight_decay_param_ids,<br>                         model.parameters())<br>    params = [&#123;<span class="hljs-string">&quot;params&quot;</span>: bert_base_params, <span class="hljs-string">&quot;lr&quot;</span>: learning_rate * bert_lr_ratio&#125;,<br>              &#123;<span class="hljs-string">&quot;params&quot;</span>: bert_no_weight_decay_params, <span class="hljs-string">&quot;lr&quot;</span>: learning_rate * bert_lr_ratio,<br>               <span class="hljs-string">&quot;weight_decay&quot;</span>: <span class="hljs-number">0.0</span>&#125;,<br>              &#123;<span class="hljs-string">&quot;params&quot;</span>: base_no_weight_decay_params, <span class="hljs-string">&quot;lr&quot;</span>: learning_rate, <span class="hljs-string">&quot;weight_decay&quot;</span>: <span class="hljs-number">0.0</span>&#125;,<br>              &#123;<span class="hljs-string">&quot;params&quot;</span>: base_params, <span class="hljs-string">&quot;lr&quot;</span>: learning_rate&#125;]<br><br>    <span class="hljs-comment"># 设置AdamW优化器</span><br>    optimizer = AdamW(params, lr=learning_rate, weight_decay=weight_decay)<br><br>    <span class="hljs-keyword">return</span> optimizer<br><br>optimizer = get_optimizer(model)<br><br></code></pre></td></tr></table></figure><h2 id="模型训练-1"><a href="#模型训练-1" class="headerlink" title="模型训练"></a>模型训练</h2><p>初始化优化器，搭建完模型网路结构后就可以开始模型训练了。一般来说模型训练的过程也比较固定，<code>模型输入-&gt;模型输出-&gt;loss计算-&gt;反向传播-&gt;优化器step-&gt;模型评估-&gt;模型保存</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> f1_score<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">evaluate</span>(<span class="hljs-params">model, data_iter</span>):<br>    model.<span class="hljs-built_in">eval</span>()<br>    loss_total = <span class="hljs-number">0</span><br>    predict_all = np.array([], dtype=<span class="hljs-built_in">int</span>)<br>    labels_all = np.array([], dtype=<span class="hljs-built_in">int</span>)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> step, batch <span class="hljs-keyword">in</span> tqdm(data_iter):<br>            batch = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> batch]<br>            outputs = model((batch[<span class="hljs-number">0</span>], batch[<span class="hljs-number">1</span>]))<br>            <span class="hljs-comment"># print(labels)</span><br>            loss = F.cross_entropy(outputs, batch[-<span class="hljs-number">1</span>])<br>            loss_total += loss<br>            labels = batch[-<span class="hljs-number">1</span>].data.cpu().numpy()<br>            predic = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu().numpy()<br>            labels_all = np.append(labels_all, labels)<br>            predict_all = np.append(predict_all, predic)<br><br>    acc = metrics.accuracy_score(labels_all, predict_all)<br>    f1 = f1_score(labels_all, predict_all, average=<span class="hljs-string">&#x27;macro&#x27;</span>)<br>    report = metrics.classification_report(labels_all, predict_all, target_names=labels_name, digits=<span class="hljs-number">4</span>)<br>    confusion = metrics.confusion_matrix(labels_all, predict_all)<br><br>    <span class="hljs-keyword">return</span> acc, f1, loss_total / (<span class="hljs-built_in">len</span>(data_iter) + <span class="hljs-number">1e-10</span>), report, confusion<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">model, test_iter</span>):<br>    <span class="hljs-comment"># test</span><br>    model.load_state_dict(torch.load(save_path))<br>    model.<span class="hljs-built_in">eval</span>()<br>    test_acc, test_f1, test_loss, test_report, test_confusion = evaluate(model, test_iter)<br>    msg = <span class="hljs-string">&#x27;Test Loss: &#123;0:&gt;5.2&#125;,  Test Acc: &#123;1:&gt;6.2%&#125;, Test F1:&#123;2:&gt;6.2%&#125;&#x27;</span><br>    logger.info(msg.<span class="hljs-built_in">format</span>(test_loss, test_acc, test_f1))<br>    logger.info(<span class="hljs-string">&quot;Precision, Recall and F1-Score...&quot;</span>)<br>    logger.info(test_report)<br>    logger.info(<span class="hljs-string">&quot;Confusion Matrix...&quot;</span>)<br>    logger.info(test_confusion)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">model, train_iter, dev_iter, test_iter, optimizer</span>):<br>    model.train()<br>    dev_best_f1 = <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;-inf&#x27;</span>)<br>    last_improve_epoch = <span class="hljs-number">0</span><br>    model.train()<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_epochs):<br>        logger.info(<span class="hljs-string">&#x27;Epoch [&#123;&#125;/&#123;&#125;]&#x27;</span>.<span class="hljs-built_in">format</span>(epoch + <span class="hljs-number">1</span>, num_epochs))<br><br>        <span class="hljs-comment"># 记录变量</span><br>        train_labels_all = np.array([], dtype=<span class="hljs-built_in">int</span>)<br>        train_predicts_all = np.array([], dtype=<span class="hljs-built_in">int</span>)<br>        train_loss_list = []<br>        t = tqdm(train_iter, leave=<span class="hljs-literal">False</span>, total=<span class="hljs-built_in">len</span>(train_iter), desc=<span class="hljs-string">&#x27;Training&#x27;</span>)<br>        <span class="hljs-keyword">for</span> step, batch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(t):<br>            batch = [x.to(device) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> batch]<br>            model.train()<br>            model.zero_grad()<br>            outputs = model((batch[<span class="hljs-number">0</span>], batch[<span class="hljs-number">1</span>]))<br>            loss = F.cross_entropy(outputs, batch[-<span class="hljs-number">1</span>])<br>            train_loss_list.append(loss.item())<br>            loss.backward()<br>            torch.nn.utils.clip_grad_norm_(model.parameters(), <span class="hljs-number">1.0</span>)  <span class="hljs-comment"># 梯度裁剪</span><br>            optimizer.step()<br>            <span class="hljs-comment"># 真实标签和预测标签</span><br><br>            predicts = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu()<br>            labels_train = batch[-<span class="hljs-number">1</span>].cpu().data.numpy()<br>            train_labels_all = np.append(train_labels_all, labels_train)<br>            train_predicts_all = np.append(train_predicts_all, predicts)<br><br>        <span class="hljs-comment"># 训练集评估</span><br>        train_loss = <span class="hljs-built_in">sum</span>(train_loss_list) / (<span class="hljs-built_in">len</span>(train_loss_list) + <span class="hljs-number">1e-10</span>)<br>        train_acc = metrics.accuracy_score(train_labels_all, train_predicts_all)<br>        train_f1 = metrics.f1_score(train_labels_all, train_predicts_all, average=<span class="hljs-string">&#x27;macro&#x27;</span>)<br><br>        dev_acc, dev_f1, dev_loss, report, confusion = evaluate(model, dev_iter)<br>        msg = <span class="hljs-string">&#x27;Train Loss: &#123;0:&gt;5.6&#125;,  Train Acc: &#123;1:&gt;6.4%&#125;,  Train F1: &#123;2:&gt;6.4%&#125;,  Val Loss: &#123;3:&gt;5.4&#125;,  Val Acc: &#123;4:&gt;6.4%&#125;,  Val F1: &#123;5:&gt;6.4%&#125;&#x27;</span><br>        logger.info(msg.<span class="hljs-built_in">format</span>(train_loss, train_acc, train_f1, dev_loss, dev_acc, dev_f1))<br>        logger.info(<span class="hljs-string">&quot;Precision, Recall and F1-Score...&quot;</span>)<br>        logger.info(report)<br>        logger.info(<span class="hljs-string">&quot;Confusion Matrix...&quot;</span>)<br>        logger.info(confusion)<br><br>        <span class="hljs-keyword">if</span> dev_f1 &gt; dev_best_f1:<br>            dev_best_f1 = dev_f1<br>            torch.save(model.state_dict(), save_path)<br>            last_improve_epoch = epoch<br><br>        <span class="hljs-keyword">if</span> epoch - last_improve_epoch &gt; patience:<br>            logger.info(<span class="hljs-string">&quot;No optimization for a long time, auto-stopping...&quot;</span>)<br>            <span class="hljs-keyword">break</span><br><br>    test(model, test_iter)<br><br>train(model,train_loader,dev_loader,test_loader,optimizer)<br><br></code></pre></td></tr></table></figure><h2 id="训练结果"><a href="#训练结果" class="headerlink" title="训练结果"></a>训练结果</h2><p>文本的实验结果如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python">023-04-<span class="hljs-number">21</span> <span class="hljs-number">16</span>:08:<span class="hljs-number">10</span>,<span class="hljs-number">560</span> - bert_cls.py[line:<span class="hljs-number">205</span>] - INFO: No optimization <span class="hljs-keyword">for</span> a long time, auto-stopping...<br><span class="hljs-number">2023</span>-04-<span class="hljs-number">21</span> <span class="hljs-number">16</span>:08:<span class="hljs-number">15</span>,<span class="hljs-number">798</span> - bert_cls.py[line:<span class="hljs-number">149</span>] - INFO: Test Loss:  <span class="hljs-number">0.52</span>,  Test Acc: <span class="hljs-number">92.00</span>%, Test F1:<span class="hljs-number">92.00</span>%<br><span class="hljs-number">2023</span>-04-<span class="hljs-number">21</span> <span class="hljs-number">16</span>:08:<span class="hljs-number">15</span>,<span class="hljs-number">798</span> - bert_cls.py[line:<span class="hljs-number">150</span>] - INFO: Precision, Recall <span class="hljs-keyword">and</span> F1-Score...<br><span class="hljs-number">2023</span>-04-<span class="hljs-number">21</span> <span class="hljs-number">16</span>:08:<span class="hljs-number">15</span>,<span class="hljs-number">798</span> - bert_cls.py[line:<span class="hljs-number">151</span>] - INFO:<br>                 precision    recall  f1-score   support<br><br>          体育     <span class="hljs-number">0.9542</span>    <span class="hljs-number">0.9580</span>    <span class="hljs-number">0.9561</span>       <span class="hljs-number">500</span><br>          娱乐     <span class="hljs-number">0.8650</span>    <span class="hljs-number">0.9480</span>    <span class="hljs-number">0.9046</span>       <span class="hljs-number">500</span><br>          家居     <span class="hljs-number">0.9502</span>    <span class="hljs-number">0.8780</span>    <span class="hljs-number">0.9127</span>       <span class="hljs-number">500</span><br>          彩票     <span class="hljs-number">0.9801</span>    <span class="hljs-number">0.9860</span>    <span class="hljs-number">0.9831</span>       <span class="hljs-number">500</span><br>          房产     <span class="hljs-number">0.8776</span>    <span class="hljs-number">0.9320</span>    <span class="hljs-number">0.9040</span>       <span class="hljs-number">500</span><br>          教育     <span class="hljs-number">0.9434</span>    <span class="hljs-number">0.9660</span>    <span class="hljs-number">0.9545</span>       <span class="hljs-number">500</span><br>          时尚     <span class="hljs-number">0.9584</span>    <span class="hljs-number">0.9220</span>    <span class="hljs-number">0.9399</span>       <span class="hljs-number">500</span><br>          时政     <span class="hljs-number">0.8945</span>    <span class="hljs-number">0.9160</span>    <span class="hljs-number">0.9051</span>       <span class="hljs-number">500</span><br>          星座     <span class="hljs-number">0.9841</span>    <span class="hljs-number">0.9920</span>    <span class="hljs-number">0.9880</span>       <span class="hljs-number">500</span><br>          游戏     <span class="hljs-number">0.9467</span>    <span class="hljs-number">0.9240</span>    <span class="hljs-number">0.9352</span>       <span class="hljs-number">500</span><br>          社会     <span class="hljs-number">0.9251</span>    <span class="hljs-number">0.9140</span>    <span class="hljs-number">0.9195</span>       <span class="hljs-number">500</span><br>          科技     <span class="hljs-number">0.8264</span>    <span class="hljs-number">0.8760</span>    <span class="hljs-number">0.8505</span>       <span class="hljs-number">500</span><br>          股票     <span class="hljs-number">0.8592</span>    <span class="hljs-number">0.8180</span>    <span class="hljs-number">0.8381</span>       <span class="hljs-number">500</span><br>          财经     <span class="hljs-number">0.9300</span>    <span class="hljs-number">0.8500</span>    <span class="hljs-number">0.8882</span>       <span class="hljs-number">500</span><br><br>    accuracy                         <span class="hljs-number">0.9200</span>      <span class="hljs-number">7000</span><br>   macro avg     <span class="hljs-number">0.9211</span>    <span class="hljs-number">0.9200</span>    <span class="hljs-number">0.9200</span>      <span class="hljs-number">7000</span><br>weighted avg     <span class="hljs-number">0.9211</span>    <span class="hljs-number">0.9200</span>    <span class="hljs-number">0.9200</span>      <span class="hljs-number">7000</span><br><br><span class="hljs-number">2023</span>-04-<span class="hljs-number">21</span> <span class="hljs-number">16</span>:08:<span class="hljs-number">15</span>,<span class="hljs-number">798</span> - bert_cls.py[line:<span class="hljs-number">152</span>] - INFO: Confusion Matrix...<br><span class="hljs-number">2023</span>-04-<span class="hljs-number">21</span> <span class="hljs-number">16</span>:08:<span class="hljs-number">15</span>,<span class="hljs-number">798</span> - bert_cls.py[line:<span class="hljs-number">153</span>] - INFO:<br> [[<span class="hljs-number">479</span>  <span class="hljs-number">13</span>   <span class="hljs-number">0</span>   <span class="hljs-number">5</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>]<br> [  <span class="hljs-number">6</span> <span class="hljs-number">474</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">0</span>   <span class="hljs-number">2</span>   <span class="hljs-number">4</span>   <span class="hljs-number">2</span>   <span class="hljs-number">2</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>]<br> [  <span class="hljs-number">0</span>   <span class="hljs-number">8</span> <span class="hljs-number">439</span>   <span class="hljs-number">0</span>  <span class="hljs-number">25</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">2</span>   <span class="hljs-number">2</span>   <span class="hljs-number">2</span>   <span class="hljs-number">2</span>  <span class="hljs-number">12</span>   <span class="hljs-number">3</span>   <span class="hljs-number">2</span>]<br> [  <span class="hljs-number">6</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span> <span class="hljs-number">493</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>]<br> [  <span class="hljs-number">1</span>   <span class="hljs-number">3</span>   <span class="hljs-number">6</span>   <span class="hljs-number">0</span> <span class="hljs-number">466</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">4</span>   <span class="hljs-number">6</span>   <span class="hljs-number">6</span>   <span class="hljs-number">5</span>]<br> [  <span class="hljs-number">0</span>   <span class="hljs-number">2</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span> <span class="hljs-number">483</span>   <span class="hljs-number">1</span>   <span class="hljs-number">2</span>   <span class="hljs-number">3</span>   <span class="hljs-number">1</span>   <span class="hljs-number">5</span>   <span class="hljs-number">2</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>]<br> [  <span class="hljs-number">1</span>  <span class="hljs-number">17</span>   <span class="hljs-number">7</span>   <span class="hljs-number">0</span>   <span class="hljs-number">7</span>   <span class="hljs-number">2</span> <span class="hljs-number">461</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">2</span>   <span class="hljs-number">2</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>]<br> [  <span class="hljs-number">1</span>   <span class="hljs-number">4</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">5</span>   <span class="hljs-number">5</span>   <span class="hljs-number">2</span> <span class="hljs-number">458</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">8</span>   <span class="hljs-number">7</span>   <span class="hljs-number">5</span>   <span class="hljs-number">4</span>]<br> [  <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">3</span>   <span class="hljs-number">0</span> <span class="hljs-number">496</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span>]<br> [  <span class="hljs-number">3</span>   <span class="hljs-number">9</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">1</span>   <span class="hljs-number">4</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span> <span class="hljs-number">462</span>   <span class="hljs-number">1</span>  <span class="hljs-number">15</span>   <span class="hljs-number">2</span>   <span class="hljs-number">0</span>]<br> [  <span class="hljs-number">4</span>   <span class="hljs-number">5</span>   <span class="hljs-number">1</span>   <span class="hljs-number">1</span>   <span class="hljs-number">1</span>  <span class="hljs-number">11</span>   <span class="hljs-number">2</span>   <span class="hljs-number">7</span>   <span class="hljs-number">0</span>   <span class="hljs-number">0</span> <span class="hljs-number">457</span>  <span class="hljs-number">10</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span>]<br> [  <span class="hljs-number">0</span>   <span class="hljs-number">8</span>   <span class="hljs-number">1</span>   <span class="hljs-number">1</span>   <span class="hljs-number">6</span>   <span class="hljs-number">3</span>   <span class="hljs-number">0</span>  <span class="hljs-number">10</span>   <span class="hljs-number">0</span>  <span class="hljs-number">12</span>   <span class="hljs-number">8</span> <span class="hljs-number">438</span>  <span class="hljs-number">12</span>   <span class="hljs-number">1</span>]<br> [  <span class="hljs-number">0</span>   <span class="hljs-number">1</span>   <span class="hljs-number">3</span>   <span class="hljs-number">0</span>  <span class="hljs-number">14</span>   <span class="hljs-number">2</span>   <span class="hljs-number">0</span>  <span class="hljs-number">21</span>   <span class="hljs-number">0</span>   <span class="hljs-number">6</span>   <span class="hljs-number">0</span>  <span class="hljs-number">25</span> <span class="hljs-number">409</span>  <span class="hljs-number">19</span>]<br> [  <span class="hljs-number">1</span>   <span class="hljs-number">3</span>   <span class="hljs-number">3</span>   <span class="hljs-number">1</span>   <span class="hljs-number">5</span>   <span class="hljs-number">1</span>   <span class="hljs-number">0</span>   <span class="hljs-number">6</span>   <span class="hljs-number">1</span>   <span class="hljs-number">1</span>   <span class="hljs-number">3</span>  <span class="hljs-number">12</span>  <span class="hljs-number">38</span> <span class="hljs-number">425</span>]]<br><br></code></pre></td></tr></table></figure><h1 id="模型预测和gradio应用简单构建"><a href="#模型预测和gradio应用简单构建" class="headerlink" title="模型预测和gradio应用简单构建"></a>模型预测和gradio应用简单构建</h1><p>训练好模型后，如果想使用模型进行预测，步骤其实和训练类似，而且不需要反向传播和任何的评价指标统计，整体流程一般是<code>输入句子-&gt;encode编码-&gt;模型输入输出-&gt;格式化输出</code>。这地方需要注意的是，如果训练保存模型的设备和加载模型的设备不一致，需要在<code>torch.load(save_path, map_location=device)</code>的时候用<code>map_location</code>参数来把二者统一起来，不然会产生模型读取错误。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertTokenizer, BertModel<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> gradio <span class="hljs-keyword">as</span> gr<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, bert_path, hidden_size, num_classes</span>):<br>        <span class="hljs-built_in">super</span>(Model, self).__init__()<br>        self.bert = BertModel.from_pretrained(bert_path)<br>        <span class="hljs-keyword">for</span> param <span class="hljs-keyword">in</span> self.bert.parameters():<br>            param.requires_grad = <span class="hljs-literal">True</span><br>        self.fc = nn.Linear(hidden_size, num_classes)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        context = x[<span class="hljs-number">0</span>]  <span class="hljs-comment"># 输入的句子</span><br>        mask = x[<span class="hljs-number">1</span>]  <span class="hljs-comment"># 对padding部分进行mask，和句子一个size，padding部分用0表示，如：[1, 1, 1, 1, 0, 0]</span><br>        _, pooled = self.bert(context, attention_mask=mask, return_dict=<span class="hljs-literal">False</span>)<br>        out = self.fc(pooled)<br>        <span class="hljs-keyword">return</span> out<br><br>dataset = <span class="hljs-string">&#x27;data/THUCnews&#x27;</span><br>labels_name = [w.strip() <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> <span class="hljs-built_in">open</span>(os.path.join(dataset, <span class="hljs-string">&#x27;class.txt&#x27;</span>), <span class="hljs-string">&#x27;r&#x27;</span>, encoding=<span class="hljs-string">&#x27;utf8&#x27;</span>).readlines()]<br>device = torch.device(<span class="hljs-string">&#x27;cpu&#x27;</span>)  <span class="hljs-comment"># 设备cpu</span><br>bert_path = <span class="hljs-string">&#x27;bert-base-chinese&#x27;</span><br>num_classes = <span class="hljs-built_in">len</span>(labels_name)<br>save_path = <span class="hljs-string">&#x27;saved_dict/bert.ckpt&#x27;</span><br>pad_size = <span class="hljs-number">32</span><br><br><span class="hljs-comment"># 用预训练的BERT模型进行初始化</span><br>tokenizer = BertTokenizer.from_pretrained(bert_path)<br>model = Model(bert_path, <span class="hljs-number">768</span>, num_classes).to(device)<br><br><span class="hljs-comment"># 加载模型权重。</span><br>model.load_state_dict(torch.load(save_path, map_location=device))<br>model.<span class="hljs-built_in">eval</span>()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">sentence</span>):<br>    inputs = tokenizer.encode(text=sentence, max_length=pad_size, truncation=<span class="hljs-literal">True</span>,<br>                              truncation_strategy=<span class="hljs-string">&#x27;longest_first&#x27;</span>,<br>                              add_special_tokens=<span class="hljs-literal">True</span>, pad_to_max_length=<span class="hljs-literal">True</span>)<br>    data_encode = (inputs, [<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> x != <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> inputs])<br>    input_id = torch.LongTensor(data_encode[<span class="hljs-number">0</span>]).unsqueeze(<span class="hljs-number">0</span>).to(device)<br>    input_mask = torch.LongTensor(data_encode[<span class="hljs-number">1</span>]).unsqueeze(<span class="hljs-number">0</span>).to(device)<br><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        outputs = model((input_id, input_mask))<br>        predicts = torch.<span class="hljs-built_in">max</span>(outputs.data, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu()<br><br>    <span class="hljs-keyword">return</span> labels_name[predicts[<span class="hljs-number">0</span>]]<br><br><span class="hljs-comment"># gradio封装</span><br>iface = gr.Interface(fn=predict, inputs=<span class="hljs-string">&quot;text&quot;</span>, outputs=<span class="hljs-string">&quot;text&quot;</span>)<br>iface.launch()<br><br></code></pre></td></tr></table></figure><h1 id="相关代码"><a href="#相关代码" class="headerlink" title="相关代码"></a>相关代码</h1><p><a href="https://github.com/leidaoyu/text_classification_demo">https://github.com/leidaoyu/text_classification_demo</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>文本分类</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MYSQL深分页性能优化</title>
    <link href="/2023/04/04/MYSQL%E6%B7%B1%E5%88%86%E9%A1%B5%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"/>
    <url>/2023/04/04/MYSQL%E6%B7%B1%E5%88%86%E9%A1%B5%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="MySQL深分页性能优化"><a href="#MySQL深分页性能优化" class="headerlink" title="MySQL深分页性能优化"></a>MySQL深分页性能优化</h1><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近在做的一个需求需要写分页查询，需要根据前端的请求返回具体页码的数据。这种分页查询看上去非常简单，通常是用select count(*)…和select … limit A,B这两条sql语句组合而成，前者获得总数，后者获得每页之中的数据。后端获得这些数据后，再组装成返回结果返回给前端。</p><p>通常这么写没有问题，但是当用户数据量极速增多，公开出去的应用非常多，导致表里数据非常大时，这时再使用select … limit A,B这种sql进行深分页就会耗时很长，从而导致以下几点问题：</p><ol><li>请求耗时长，影响用户体验</li><li>消耗过多MySQL机器的CPU资源，影响其他查询操作</li><li>服务器堆积大量请求，容易耗尽线程，影响其他操作</li></ol><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>先看一下select … limit A,B这种sql语句的问题在哪。先随便准备一张表，包含主键id和create_time以及其他一些字段，再往里面插入100万+的数据。</p><p>执行以下SQL语句</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t2 <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> create_time <span class="hljs-keyword">desc</span> limit <span class="hljs-number">10</span>, <span class="hljs-number">20</span>;<br></code></pre></td></tr></table></figure><p>观察它的耗时时间仅为23ms，没什么问题</p><p><img src="https://s3.bmp.ovh/imgs/2023/04/04/a551e91ad75cb99a.png" alt="Untitled"></p><p>这时我们模拟用户的深分页请求，将offset参数调到1000000，执行以下SQL语句</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t2 <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> create_time <span class="hljs-keyword">desc</span> limit <span class="hljs-number">1000000</span>, <span class="hljs-number">20</span>;<br></code></pre></td></tr></table></figure><p>这时它的耗时到了923ms，是之前的40多倍。如果MySQL机器用的是机械硬盘的话这个时间会更长。</p><p><img src="https://s3.bmp.ovh/imgs/2023/04/04/9b6cdb6b7b5e2bf5.png" alt="Untitled"></p><h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><p>出现上个问题的原因是MySQL在执行select * from t2 order by create_time desc limit 1000000, 20这种语句时，不会直接定位到第1000000行数据，返回后面的20条，而是会<strong>从头开始扫描得到1000020行数据，返回的时候丢弃前1000000行数据只返回后20行</strong>。</p><p>使用explain看它的执行情况，扫描行数到了1038187行</p><p><img src="https://s3.bmp.ovh/imgs/2023/04/04/25f5b6d1c811a2b0.png" alt="Untitled"></p><p>在有索引的情况下，我们看一下select * from t2 order by create_time desc limit A, B这种语句的执行过程</p><ol><li>先到create_time的索引树上找到降序排序的第一条数据，在叶子结点中找到对应的主键值（二级索引树上的叶子结点保存的是主键值而非行数据）</li><li>再用这个主键值到主键索引树上找到对应的行数据，这个操作称之为回表</li><li>重复以上两个操作大概A+B次，丢弃前面A行数据，返回后B行数据</li></ol><p>观察上面的执行过程，很容易发现前面A行数据的回表操作是完全没有必要的，因为最后返回的时候还会把这些数据丢弃。</p><p>还有一点需要注意的是，即使排序字段加了索引但是由于扫描和回表行数太多，MySQL的优化器会选择全表扫描，再将得到的结果进行一个外部排序。比如select * from t2 order by create_time desc limit 1000000, 20这种offeset很大的深分页语句。</p><h1 id="使用覆盖索引优化"><a href="#使用覆盖索引优化" class="headerlink" title="使用覆盖索引优化"></a>使用覆盖索引优化</h1><p>针对这种深分页的sql语句最典型的解决方法就是使用覆盖索引减少回表操作进行优化。</p><p>我们执行下面这行语句:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t2, (<span class="hljs-keyword">select</span> id <span class="hljs-keyword">from</span> t2 <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> create_time <span class="hljs-keyword">desc</span> limit <span class="hljs-number">1000000</span>, <span class="hljs-number">20</span>) temp <span class="hljs-keyword">where</span> temp.id <span class="hljs-operator">=</span> t2.id;<br></code></pre></td></tr></table></figure><p>这行语句跟select * from t2 order by create_time desc limit 1000000, 20的执行效果是一模一样的，但是它的执行时间只有161ms，远远小于之前执行的900多毫秒</p><p><img src="https://s3.bmp.ovh/imgs/2023/04/04/36d6244afd47c46c.png" alt="Untitled"></p><p>这条sql之所以快的原因就在于其中的一条子查询语句</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> id <span class="hljs-keyword">from</span> t2 <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> create_time <span class="hljs-keyword">desc</span> limit <span class="hljs-number">1000000</span>, <span class="hljs-number">20</span><br></code></pre></td></tr></table></figure><p>这条语句会在create_time的索引树上扫描找到符合条件的id，虽然也会扫描1000020行，但是由于二级索引树的叶子结点本身就保存了主键id值，无需回表，所以这个子查询执行的速度非常快。<strong>这种在索引树上就能获得值而无需去回表查询的方式叫做覆盖索引</strong>。</p><p>覆盖索引：索引是高效找到行的一个方法，当能通过检索索引就可以读取想要的数据，那就不需要再到数据表中读取行了。如果一个索引包含了（或覆盖了）满足查询语句中字段与条件的数据就叫做覆盖索引。</p><p>再回头看上面这行语句</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t2, (<span class="hljs-keyword">select</span> id <span class="hljs-keyword">from</span> t2 <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> create_time <span class="hljs-keyword">desc</span> limit <span class="hljs-number">1000000</span>, <span class="hljs-number">20</span>) temp <span class="hljs-keyword">where</span> temp.id <span class="hljs-operator">=</span> t2.id;<br></code></pre></td></tr></table></figure><p>这条语句其中的子查询已经找到了符合条件的id值，只需要对这20行id值做回表操作即可拿到想要的数据，省去了之前1000000行数据的回表操作，从而提升查询速度。这种优化方法也叫做延迟关联。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> ... <span class="hljs-keyword">where</span> ... limit A, B<br></code></pre></td></tr></table></figure><p>一般来讲，上面这种普通的分页查询都可以通过延迟关联优化成下面这种sql</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> t, (<span class="hljs-keyword">select</span> id form t <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> ... <span class="hljs-keyword">where</span> ... limit A, B) temp <span class="hljs-keyword">where</span> t.id <span class="hljs-operator">=</span> temp.id<br></code></pre></td></tr></table></figure><h1 id=""><a href="#" class="headerlink" title=""></a></h1>]]></content>
    
    
    
    <tags>
      
      <tag>中间件</tag>
      
      <tag>mysql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kafka简介与使用场景</title>
    <link href="/2023/03/31/Kafka%E7%AE%80%E4%BB%8B%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <url>/2023/03/31/Kafka%E7%AE%80%E4%BB%8B%E4%B8%8E%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="Kafka简介与使用场景"><a href="#Kafka简介与使用场景" class="headerlink" title="Kafka简介与使用场景"></a>Kafka简介与使用场景</h1><h1 id="为什么要引入消息队列"><a href="#为什么要引入消息队列" class="headerlink" title="为什么要引入消息队列"></a>为什么要引入消息队列</h1><p>假设我们现在有一个在线购物网站，用户在网站上下单购买商品，网站需要向订单系统发送订单信息，订单系统再根据订单信息进行处理和发货，如果我们不引入任何中间件，网站和订单系统之间的交互可能会出现以下问题：</p><ol><li>高并发流量导致宕机：当用户下单并提交订单后，网站需要立即向订单系统发送订单信息，如果此时用户量很大，会导致高并发流量，容易使网站宕机或响应时间过长，影响用户体验和业务运营。</li><li>系统耦合度高：如果网站直接调用订单系统的 API 来处理订单信息，会导致网站和订单系统之间的耦合度高，使得系统难以扩展和维护。</li><li>单点故障：如果网站和订单系统之间采用同步的方式进行交互，会使得网站和订单系统之间出现单点故障，当其中一个系统出现问题时，整个系统都将受到影响。</li><li>数据不一致：如果网站和订单系统之间采用异步的方式进行交互，但是没有消息队列的支持，可能会导致数据不一致的问题。例如，当网站发送订单信息到订单系统后，由于网络问题或者订单系统出现问题，订单系统无法处理订单信息，会导致订单信息丢失或者延迟，从而使得网站和订单系统之间的数据不一致。</li></ol><p><img src="https://s3.bmp.ovh/imgs/2023/03/31/99cc342194486e05.png" alt="非消息队列"></p><p>为了解决以上问题，我们可以考虑将用户下单的订单信息写入消息队列中，订单系统异步地从队列中读取订单信息，并进行处理和发货。由于订单系统是异步处理订单信息，因此可以避免网站因为高并发流量而宕机，同时也降低了网站和订单系统之间的耦合度，提高了系统的可扩展性和可维护性。</p><p>此外，如果有多个订单系统需要处理订单信息，也可以通过消息队列来实现数据分发和共享，将订单信息写入消息队列中，各个订单系统可以异步地从队列中读取订单信息进行处理，提高了订单信息的利用率和共享效率。</p><p><img src="https://s3.bmp.ovh/imgs/2023/03/31/a4ad2a275e58fa01.png" alt="消息队列"></p><p>通过以上实例，可以看出消息队列在电商购物场景中的作用和必要性，包括解耦、流量削峰、异步处理、数据分发和共享等。同时，消息队列也可以通过水平扩展和容错机制来提高系统的可伸缩性和可靠性，是实现大规模高并发系统的重要技术手段之一。</p><h1 id="Kafka是什么"><a href="#Kafka是什么" class="headerlink" title="Kafka是什么"></a>Kafka是什么</h1><p>Kafka是一个由Scala和Java编写的企业级的消息发布和订阅系统，最早是由Linkedin公司开发，最终开源到Apache软件基金会的项目。Kafka是一个分布式的，支持分区的，多副本的和多订阅者的高吞吐量的消息队列系统，被广泛应用在应用解耦、异步处理、限流削峰和消息驱动等场景。</p><h1 id="Kafka的架构和基本概念"><a href="#Kafka的架构和基本概念" class="headerlink" title="Kafka的架构和基本概念"></a>Kafka的架构和基本概念</h1><p><img src="https://s3.bmp.ovh/imgs/2023/03/31/fc4ad56f4390f436.png" alt="Kafka架构"></p><ol><li><p>Topic：消息的类别，主要用于对消息进行逻辑上的区分，每条发送到Kafka集群的消息都需要有一个指定的Topic，消费者根据Topic对指定的消息进行消费，类似于关系数据库的表，需要获取什么topic的信息就监听对应的topic即可</p><p> <img src="https://s3.bmp.ovh/imgs/2023/03/31/41cbeff00ace1798.png" alt="Topic"></p></li><li><p>Partition：消息的分区，Partition是一个物理上的概念，相当于一个文件夹，Kafka会为每个topic的每个分区创建一个文件夹，一个Topic的消息会存储在一个或者多个Partition中，Topic 是一个逻辑概念，而 Partition 是分布式存储单元。</p><p> <img src="https://s3.bmp.ovh/imgs/2023/03/31/481901aa00c0a1fe.png" alt="Partition"></p></li><li><p>Producer：Producer是Kafka中的消息生产者，主要用于生产带有特定Topic的消息，生产者生产的消息通过Topic进行归类，保存在Kafka 集群的Broker上，具体的是保存在指定的partition 的目录下，以Segment的方式（.log文件和.index文件）进行存储</p></li><li><p>Consumer：Consumer是Kafka中的消费者，主要用于消费指定Topic的消息，Consumer是通过主动拉取的方式从Kafka集群中消费消息，消费者一定属于某一个特定的消费组。</p></li><li><p>Message：Message是实际发送和订阅的信息是实际载体，Producer发送到Kafka集群中的每条消息，都被Kafka包装成了一个Message对象，之后再存储在磁盘中，而不是直接存储的。</p></li><li><p>Consumer Group：每个Consumer属于一个特定的Consumer Group，新建Consumer的时候需要指定对应的Consumer Group ID</p><p> 我们在消费数据时会在代码里面指定一个group.id，这个 id 代表的是消费组的名字，而且这个 group.id就算不设置，系统也会默认设置：</p> <figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs pf">conf.<span class="hljs-built_in">set</span>Property(<span class="hljs-string">&quot;group.id&quot;</span>,<span class="hljs-string">&quot;tellYourDream&quot;</span>)<br></code></pre></td></tr></table></figure><p> 我们所熟知的一些消息系统一般来说会这样设计，就是只要有一个消费者去消费了消息系统里面的数据，那么其余所有的消费者都不能再去消费这个数据。可是 Kafka 并不是这样，比如现在 ConsumerA 去消费了一个 TopicA 里面的数据：</p> <figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">consumerA:</span><br>    <span class="hljs-string">group.id</span> <span class="hljs-string">=</span> <span class="hljs-string">a</span><br><span class="hljs-attr">consumerB:</span><br>    <span class="hljs-string">group.id</span> <span class="hljs-string">=</span> <span class="hljs-string">a</span><br> <br><span class="hljs-attr">consumerC:</span><br>    <span class="hljs-string">group.id</span> <span class="hljs-string">=</span> <span class="hljs-string">b</span><br><span class="hljs-attr">consumerD:</span><br>    <span class="hljs-string">group.id</span> <span class="hljs-string">=</span> <span class="hljs-string">b</span><br></code></pre></td></tr></table></figure><p> 再让 ConsumerB 也去消费 TopicA 的数据，它是消费不到了，但是我们在 ConsumerC 中重新指定一个另外的 group.id，ConsumerC 是可以消费到 TopicA 的数据的，而 ConsumerD 也是消费不到的，所以在 Kafka 中，不同组可有唯一的一个消费者去消费同一主题的数据。</p><p> 消费者组就是让多个消费者并行消费信息而存在的，而且它们不会消费到同一个消息。</p></li><li><p>Broker：Kafka集群中的服务实例，也称之为节点，每个Kafka集群包含一个或者多个Broker（一个Broker就是一个服务器或节点）</p></li><li><p>Segment：一个partition当中存在多个segment文件段（分段存储），每个Segment分为两部分，.log文件和 .index 文件，其中 .index 文件是索引文件，主要用于快速查询.log 文件当中数据的偏移量位置</p><ol><li>.log文件：存放Message的数据文件，在Kafka中把数据文件就叫做日志文件。一个分区下面默认有n多个.log文件（分段存储）。一个.log文件大默认1G，消息会不断追加在.log文件中，当.log文件的大小超过1G的时候，会自动新建一个新的.log文件</li><li>.index文件：存放.log文件的索引数据，每个.index文件有一个对应同名的.log文件。</li></ol></li></ol><h1 id="Kafka高性能的实现"><a href="#Kafka高性能的实现" class="headerlink" title="Kafka高性能的实现"></a>Kafka高性能的实现</h1><h2 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h2><h3 id="传统的拷贝过程"><a href="#传统的拷贝过程" class="headerlink" title="传统的拷贝过程"></a>传统的拷贝过程</h3><ol><li>操作系统将数据从磁盘文件中读取到内核空间的页面缓存；</li><li>应用程序将数据从内核空间读入用户空间缓冲区；</li><li>应用程序将读到数据写回内核空间并放入socket缓冲区；</li><li>操作系统将数据从socket缓冲区复制到网卡接口，此时数据才能通过网络发送。</li></ol><p>这个过程涉及到 4 次上下文切换以及 4 次数据的复制，并且有两次复制操作是由 CPU 完成。但是这个过程中，数据完全没有进行变化，仅仅是从磁盘复制到网卡缓冲区。</p><p>在这种情况下，如果能够减少用户空间与内核空间之间的切换，即去掉2和3流程，比传统性能高。这样子首先数据被从磁盘读取到 Read Buffer 中，然后再发送到 Socket Buffer，最后才发送到网卡。虽然减少了用户空间和内核空间之间的数据交换，但依然存在多次数据复制。</p><p>可以看出性能都消耗在彼此之间的数据复制过程中，那么进一步减少数据的复制过程，或者干脆没有数据复制这一过程，性能会明显增强。这就是DMA技术了。</p><p><img src="https://s3.bmp.ovh/imgs/2023/03/31/1b77c145217d0c5f.png" alt="传统拷贝过程">)</p><h3 id="DMA技术"><a href="#DMA技术" class="headerlink" title="DMA技术"></a>DMA技术</h3><p>DMA(Direct Memory Access，直接存储器访问) 是所有现代电脑的重要特色，它允许不同速度的硬件装置来沟通，而不需要依赖于CPU的大量中断负载。否则，CPU 需要从来源把每一片段的资料复制到暂存器，然后把它们再次写回到新的地方。在这个时间中，CPU 对于其他的工作来说就无法使用。</p><p>传统的内存访问，所有的请求都会发送到 CPU ，然后再由 CPU 来完成相关调度工作。当 DMA 技术的出现，数据文件在各个层之间的传输，则可以直接绕过CPU，使得外围设备可以通过DMA控制器直接访问内存。与此同时，CPU可以继续执行程序。</p><p>现在电脑中很多硬件都是支持 DMA 技术的，这里面其中就包括我们此处用到的网卡。</p><h3 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a><strong><strong>零拷贝技术</strong></strong></h3><p>有了 DMA 技术的，通过网卡直接去访问系统的内存，就可以实现现绝对的零拷贝了。这样就可以最大程度提高传输性能。通过“零拷贝”技术，我们可以去掉那些没必要的数据复制操作， 同时也会减少上下文切换次数。</p><p><img src="https://s3.bmp.ovh/imgs/2023/03/31/4bb458df09a83c4b.png" alt="DMA"></p><h2 id="顺序写"><a href="#顺序写" class="headerlink" title="顺序写"></a>顺序写</h2><p>Kafka是将消息记录持久化到本地磁盘中的，有的人会认为磁盘读写性能差，可能会对Kafka性能如何保证提岀质疑。实际上不管是内存还是磁盘，快或慢关键在于寻址的方式，磁盘分为顺序读写与随机读写，内存也一样分为顺序读写与随机读写。基于磁盘的随机读写确实很慢，但磁盘的顺序读写性能却很高，一般而言要高岀磁盘随机读写三个数量级，一些情况下磁盘顺序读写性能甚至要高于内存随机读写。</p><p>磁盘的顺序读写是磁盘使用模式中最有规律的，并且操作系统也对这种模式做了大 量优化，Kafka就是使用了磁盘顺序读写来提升的性能。Kafka的message是不断 追加到本地磁盘文件末尾的，而不是随机的写入，这使得Kafka写入吞吐量得到了显著提升。</p><p>具体来说，kafka的日志文件都是一个 log entrie 序列，每个 log entrie 包含一个 4 字节整型数值（值为 N+5），1 个字节的 “magic value”，4 个字节的 CRC 校验码，其后跟 N 个字节的消息体。每条消息都有一个当前 Partition 下唯一的 64 字节的 offset，它指明了这条消息的起始位置。磁盘上存储的消息格式如下：</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">message <span class="hljs-built_in">length</span> ： <span class="hljs-number">4</span> <span class="hljs-keyword">bytes</span> (<span class="hljs-built_in">value</span>: <span class="hljs-number">1</span>+<span class="hljs-number">4</span>+n)<br><span class="hljs-string">&quot;magic&quot;</span> <span class="hljs-built_in">value</span> ： <span class="hljs-number">1</span> <span class="hljs-keyword">byte</span><br>crc ： <span class="hljs-number">4</span> <span class="hljs-keyword">bytes</span><br>payload ： n <span class="hljs-keyword">bytes</span><br></code></pre></td></tr></table></figure><p>这个 log entries 并非由一个文件构成，而是分成多个 segment，每个 segment 以该 segment 第一条消息的 offset 命名并以“.kafka”为后缀。另外会有一个索引文件，它标明了每个 segment 下包含的 log entry 的 offset 范围，如下图所示:</p><p><img src="https://s3.bmp.ovh/imgs/2023/03/31/5dc7d3bae1546566.png" alt="log"></p><p>因为每条消息都被 append 到该 Partition 中，属于顺序写磁盘，因此效率非常高。</p><p><img src="https://s3.bmp.ovh/imgs/2023/03/31/3c5d3e8a6fb78598.png" alt="append"></p><h1 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h1><p>Kafka 作为一款高性能的分布式消息队列系统，广泛应用于各种大数据场景中。下面列举几个常见的应用场景：</p><ol><li>日志收集：在分布式系统中，日志是非常重要的一部分，通过将日志写入 Kafka 中，可以方便地进行收集、存储、处理和分析。例如，通过将应用程序的日志写入 Kafka 中，可以实现集中式的日志收集和分析，帮助开发人员快速定位和解决问题。</li><li>流式处理：Kafka 可以实现流式数据的收集、存储和分析，支持实时的数据流处理和实时数据的转换。例如，将 IoT 设备的数据写入 Kafka 中，通过流处理工具（例如 Apache Flink）进行实时的数据分析和计算，可以帮助企业更好地了解用户需求和行为，优化产品和服务。</li><li>消息系统：Kafka 可以作为消息系统，实现异步通信和消息传递，将应用程序解耦并提高系统的可伸缩性。例如，在一个微服务架构中，可以使用 Kafka 作为消息中间件，将各个服务之间的消息进行异步通信和传递，实现服务之间的解耦和流量削峰。</li><li>测试数据生成：在进行系统测试和性能测试时，通常需要生成大量的测试数据。通过将测试数据写入 Kafka 中，可以方便地生成大规模的测试数据，提高测试效率和测试覆盖率。</li><li>实时监控和报警：通过将系统的监控数据写入 Kafka 中，可以方便地进行实时监控和报警，及时发现和解决系统问题。例如，在分布式系统中，通过将各个节点的监控数据写入 Kafka 中，可以实时监控系统的健康状态，及时发现故障并进行处理。</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>中间件</tag>
      
      <tag>Kafka</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>k8s本地联调工具——kt-connect</title>
    <link href="/2023/02/21/k8s%E6%9C%AC%E5%9C%B0%E8%81%94%E8%B0%83%E5%B7%A5%E5%85%B7%E2%80%94%E2%80%94kt-connect/"/>
    <url>/2023/02/21/k8s%E6%9C%AC%E5%9C%B0%E8%81%94%E8%B0%83%E5%B7%A5%E5%85%B7%E2%80%94%E2%80%94kt-connect/</url>
    
    <content type="html"><![CDATA[<h1 id="k8s本地联调工具——kt-connect"><a href="#k8s本地联调工具——kt-connect" class="headerlink" title="k8s本地联调工具——kt-connect"></a>k8s本地联调工具——kt-connect</h1><h1 id="开发者痛点"><a href="#开发者痛点" class="headerlink" title="开发者痛点"></a>开发者痛点</h1><p>在微服务开发的工作中，开发者常常会遇见这样一个问题：</p><p>本地开发了一个接口新功能或者需要对某个接口进行bug调试，一般的做法就是本地起服务，然后用postman等工具去构造请求进行测试。但是有时候微服务会依赖其他服务，服务之间用feign等方法调用，导致接口测试不通，死办法可以把k8s上被依赖的服务开放几个公网端口，通过修改feign的url进行调用，或者把被依赖的服务也在本地启动，完全本地测试。</p><p>这两种方法在简单的微服务调用情况下不失为一种方式，但是如果服务A→B，而且B→C，C→D…采用之前的死办法会让本地起的服务越来越多，同时每个服务一般都有dev、staging、prod等环境，不同环境配置也不一样，稍不留神就会出错。我们下意识的就会希望有一种方式可以把打到k8s上的请求转到本地，这样就可以非常方便的进行接口测试或者debug了，kt-connect就能很好的满足这个需求。</p><h1 id="Kt-connect简介"><a href="#Kt-connect简介" class="headerlink" title="Kt-connect简介"></a>Kt-connect简介</h1><p><a href="https://alibaba.github.io/kt-connect/#/">KT Connect （ Kubernetes Developer Tool</a> ） 是轻量级的面向 Kubernetes 用户的开发测试环境治理辅助工具。其核心是通过建立本地到集群以及集群到本地的双向通道，从而提升在持续交付生命周期中开发环节的效率问题以及开发测试环境的复用问题。</p><p><img src="https://s3.bmp.ovh/imgs/2023/02/21/f7e1b7bc638cba2a.png" alt="k8s结构图"></p><h1 id="Kt-connect能帮我们实现什么"><a href="#Kt-connect能帮我们实现什么" class="headerlink" title="Kt-connect能帮我们实现什么"></a>Kt-connect能帮我们实现什么</h1><ol><li><p>直接访问Kubernetes集群</p><p> 开发者通过KT可以直接连接Kubernetes集群内部网络，在不修改代码的情况下完成本地开发与联调测试</p></li><li><p>转发集群流量到本地</p><p> 开发者可以将集群中的流量转发到本地，从而使得集群中的其它服务可以联调本地</p></li><li><p>Service Mesh支持</p><p> 对于使用Istio的开发者，KT支持创建一个指向本地的Version版本</p></li><li><p>基于SSH的轻量级VPN网络</p><p> KT使用shhuttle作为网络连接实现，实现轻量级的SSH VPN网络</p></li><li><p>作为kubectl插件，集成到Kubectl</p><p> 开发者也可以直接将ktctl集成到kubectl中</p></li></ol><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="Macos"><a href="#Macos" class="headerlink" title="Macos"></a>Macos</h2><p>推荐使用**<a href="https://brew.sh/">Homebrew</a>**工具一键安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">brew install kt-connect<br></code></pre></td></tr></table></figure><hr><p>也可以手工下载最新软件包:</p><ul><li><strong><a href="https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_MacOS_x86_64.tar.gz">MacOS x86 64位</a></strong></li><li><strong><a href="https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_MacOS_arm_64.tar.gz">MacOS ARM 64位</a></strong></li></ul><p>通过命令行下载并安装KT（以x86 64位版本为例）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl -OL https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_MacOS_x86_64.tar.gz<br>$ tar zxf ktctl_0.3.7_MacOS_x86_64.tar.gz<br>$ <span class="hljs-built_in">mv</span> ktctl /usr/local/bin/ktctl<br>$ ktctl --version<br></code></pre></td></tr></table></figure><blockquote><p>可以从<a href="https://github.com/alibaba/kt-connect/releases">Github Releases</a>下载历史版本的软件包</p></blockquote><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p>最新软件包:</p><ul><li><strong><a href="https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_Linux_x86_64.tar.gz">Linux x86 64位</a></strong></li><li><strong><a href="https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_linux_i386.tar.gz">Linux x86 32位</a></strong></li><li><strong><a href="https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_Linux_arm_64.tar.gz">Linux ARM 64位</a></strong></li></ul><p>下载并安装KT（以x86 64位版本为例）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl -OL https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_Linux_x86_64.tar.gz<br>$ tar zxf ktctl_0.3.7_Linux_x86_64.tar.gz<br>$ <span class="hljs-built_in">mv</span> ktctl /usr/local/bin/ktctl<br>$ ktctl --version<br></code></pre></td></tr></table></figure><blockquote><p>可以从<a href="https://github.com/alibaba/kt-connect/releases">Github Releases</a>下载历史版本的软件包</p></blockquote><h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2><p>最新软件包:</p><ul><li><strong><a href="https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_Windows_x86_64.zip">Windows x86 64位</a></strong></li><li><strong><a href="https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_Windows_i386.zip">Windows x86 32位</a></strong></li><li><strong><a href="https://github.com/alibaba/kt-connect/releases/download/v0.3.7/ktctl_0.3.7_Windows_arm_64.zip">Windows ARM 64位</a></strong></li></ul><p>下载并解压，将包中的<code>wintun.dll</code>和可执行文件<code>ktctl.exe</code>一起放到<code>PATH</code>环境变量指定的任意位置。</p><blockquote><p>可以从<a href="https://github.com/alibaba/kt-connect/releases">Github Releases</a>下载历史版本的软件包</p></blockquote><h1 id="常见操作"><a href="#常见操作" class="headerlink" title="常见操作"></a>常见操作</h1><p>kt-connect会在指定连接的命名空间（namespace）里面新建一个自用的pod，然后部署一个kt-connect-shadow的镜像：</p><ul><li><code>Connect</code>：建立数据代理通道，实现本地服务直接访问Kubernetes集群内网（包括Pod IP和Service域名）</li><li><code>Exchange</code>：让集群服务流量重定向到本地，实现快速验证本地版本和调试排查问题</li><li><code>Mesh</code>：创建路由规则重定向特定流量，实现多人协作场景下互不影响的本地调试</li><li><code>Preview</code>：暴露本地服务到集群，实现无需发布即可在线预览集成效果</li></ul><h2 id="Connect"><a href="#Connect" class="headerlink" title="Connect"></a>Connect</h2><p><code>ktctl connect</code>可以将本地环境连接至k8s集群，看到<code>All looks good, now you can access to resources in the kubernetes cluster</code>表示连接成功</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs text">$ sudo ktctl connect --namespace test<br><br>5:31PM INF Using cluster context kubernetes-admin@kubernetes (kubernetes)<br>5:31PM INF KtConnect 0.3.6 start at 91483 (darwin amd64)<br>5:31PM INF Fetching cluster time ...<br>5:31PM INF Using tun2socks mode<br>5:31PM INF Successful create config map kt-connect-shadow-jhqrg<br>5:31PM INF Deploying shadow pod kt-connect-shadow-jhqrg in namespace test<br>......<br>5:31PM INF Setup local DNS with upstream [tcp:127.0.0.1:20626 udp:192.168.9.200:53]<br>5:31PM INF Creating udp dns on port 10053<br>5:31PM INF ---------------------------------------------------------------<br>5:31PM INF  All looks good, now you can access to resources in the kubernetes cluster<br>5:31PM INF ---------------------------------------------------------------<br><br>#这里名称空间我选择的test，因为我测试服务起在这个名称空间下<br></code></pre></td></tr></table></figure><h2 id="Exchange"><a href="#Exchange" class="headerlink" title="Exchange"></a>Exchange</h2><p><img src="https://s3.bmp.ovh/imgs/2023/02/21/34a2aa187417fc6f.png" alt="exchange"></p><p>当看到<code>Now all request to service &#39;&#123;your_service_in_k8s&#125;&#39; will be redirected to local</code> 的时候说明k8s的请求都被转到本地</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs text">ktctl exchange -n &#123;your_namespace_in_k8s&#125; &#123;your_service_in_k8s&#125; --expose &#123;your_local_service_port_in_k8s&#125;:&#123;your_service_target_port_in_k8s&#125;<br><br>12:39PM INF Using cluster context &#123;k8s_cluster_context&#125; (&#123;k8s_cluster_context&#125;)<br>12:39PM INF KtConnect 0.3.6 start at 28585 (linux amd64)<br>12:39PM INF Fetching cluster time ...<br>12:39PM INF Using selector mode<br>12:39PM INF Service &#123;your_service_in_k8s&#125; locked<br>12:39PM INF Successful create config map &#123;your_service_in_k8s&#125;-kt-exchange-zikkt<br>12:39PM INF Deploying shadow pod aide-be-service-kt-exchange-zikkt in namespace &#123;your_namespace_in_k8s&#125;<br>12:39PM INF Waiting for pod &#123;your_service_in_k8s&#125;-kt-exchange-zikkt ...<br>12:39PM INF Pod &#123;your_service_in_k8s&#125;-kt-exchange-zikkt is ready<br>12:39PM INF Forwarding pod &#123;your_service_in_k8s&#125;-kt-exchange-zikkt to local via port &#123;your_local_service_port_in_k8s&#125;&#125;:&#123;your_service_target_port_in_k8s&#125;<br>12:39PM INF Port forward local:41512 -&gt; pod &#123;your_service_in_k8s&#125;-kt-exchange-zikkt:22 established<br>12:39PM INF Reverse tunnel 0.0.0.0:&#123;your_local_service_port_in_k8s&#125;&#125; -&gt; 127.0.0.1:&#123;your_service_target_port_in_k8s&#125; established<br>12:39PM INF Service aide-be-service unlocked<br>12:39PM INF ---------------------------------------------------------------<br>12:39PM INF  Now all request to service &#x27;&#123;your_service_in_k8s&#125;&#x27; will be redirected to local<br>12:39PM INF ---------------------------------------------------------------<br>^C12:39PM INF Terminal Signal is interrupt<br>12:39PM INF Removed pid file /home/PJLAB/leidaoyu/.kt/pid/exchange-28585.pid<br>12:39PM INF Removed key file /home/PJLAB/leidaoyu/.kt/key/aide-be-service-kt-exchange-zikkt.key<br>12:39PM INF Pid file was removed<br>12:39PM INF Original service aide-be-service recovered<br>12:39PM INF Cleaning configmap aide-be-service-kt-exchange-zikkt<br>12:39PM INF Cleaning shadow pod aide-be-service-kt-exchange-zikkt<br></code></pre></td></tr></table></figure><h2 id="Mesh"><a href="#Mesh" class="headerlink" title="Mesh"></a>Mesh</h2><p><img src="https://s3.bmp.ovh/imgs/2023/02/21/ea7173bfc8ee8c9e.png" alt="mesh"></p><p>当看到<code>Now you can access your service by header &#39;VERSION: jnuie&#39;</code> 的时候说明k8s的请求都被转到本地，在向k8s发请求的时候在header里面加入<code>VERSION: jnuie</code> 参数，请求就会被转发回本地</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs text">ktctl exchange -n &#123;your_namespace_in_k8s&#125; &#123;your_service_in_k8s&#125; --expose &#123;your_local_service_port_in_k8s&#125;:&#123;your_service_target_port_in_k8s&#125;<br>1:21PM INF Using cluster context &#123;k8s_cluster_context&#125; (&#123;k8s_cluster_context&#125;)<br>1:21PM INF KtConnect 0.3.6 start at 2965 (linux amd64)<br>1:21PM INF Fetching cluster time ...<br>1:21PM INF Using auto mode<br>1:21PM INF Service &#123;your_service_in_k8s&#125;e locked<br>1:21PM INF Service &#123;your_service_in_k8s&#125;e-kt-stuntman created<br>1:21PM INF Service &#123;your_service_in_k8s&#125;-kt-mesh-jnuie created<br>1:21PM INF Router pod &#123;your_service_in_k8s&#125;-kt-router created<br>1:21PM INF Waiting for pod &#123;your_service_in_k8s&#125;-kt-router ...<br>1:21PM INF Pod &#123;your_service_in_k8s&#125;-kt-router is ready<br>1:21PM INF Router pod is ready<br>1:21PM INF Router pod configuration done<br>1:21PM INF Successful create config map &#123;your_service_in_k8s&#125;-kt-mesh-jnuie<br>1:21PM INF Deploying shadow pod &#123;your_service_in_k8s&#125;-kt-mesh-jnuie in namespace &#123;your_namespace_in_k8s&#125;<br>1:21PM INF Waiting for pod &#123;your_service_in_k8s&#125;-kt-mesh-jnuie ...<br>1:21PM INF Pod &#123;your_service_in_k8s&#125;-kt-mesh-jnuie is ready<br>1:21PM INF Forwarding pod &#123;your_service_in_k8s&#125;-kt-mesh-jnuie to local via port &#123;your_local_service_port_in_k8s&#125;:&#123;your_service_target_port_in_k8s&#125;<br>1:21PM INF Port forward local:54156 -&gt; pod aide-be-service-kt-mesh-jnuie:22 established<br>1:21PM INF Reverse tunnel 0.0.0.0:&#123;your_local_service_port_in_k8s&#125; -&gt; 127.0.0.1:&#123;your_service_target_port_in_k8s&#125; established<br>1:21PM INF ---------------------------------------------------------------<br>1:21PM INF  Now you can access your service by header &#x27;VERSION: jnuie&#x27;<br>1:21PM INF ---------------------------------------------------------------<br>1:21PM INF Service aide-be-service unlocked<br></code></pre></td></tr></table></figure><h1 id="nacos服务发现注意事项"><a href="#nacos服务发现注意事项" class="headerlink" title="nacos服务发现注意事项"></a>nacos服务发现注意事项</h1><p>如果微服务的负载均衡是通过第三方组件完成的，如nacos的服务发现，则feign配置需要修改，url需要设置成k8s的ingress上的地址</p><p><img src="https://s3.bmp.ovh/imgs/2023/02/21/d00a1ef789408610.png" alt="ingress"></p>]]></content>
    
    
    
    <tags>
      
      <tag>容器</tag>
      
      <tag>中间件</tag>
      
      <tag>工具</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>K8S介绍和基本操作</title>
    <link href="/2023/02/04/K8S%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    <url>/2023/02/04/K8S%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="K8S介绍和基本操作"><a href="#K8S介绍和基本操作" class="headerlink" title="K8S介绍和基本操作"></a>K8S介绍和基本操作</h1><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>Kubernetes 是一个可移植、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。 Kubernetes 拥有一个庞大且快速增长的生态，其服务、支持和工具的使用范围相当广泛。</p><p><strong>Kubernetes</strong> 这个名字源于希腊语，意为“舵手”或“飞行员”。k8s 这个缩写是因为 k 和 s 之间有八个字符的关系。 Google 在 2014 年开源了 Kubernetes 项目。 Kubernetes 建立在 Google 大规模运行生产工作负载十几年经验的基础上， 结合了社区中最优秀的想法和实践。</p><p>Kubernetes 为你提供：</p><ul><li><p><strong>服务发现和负载均衡</strong></p><p>  Kubernetes 可以使用 DNS 名称或自己的 IP 地址来暴露容器。 如果进入容器的流量很大， Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p></li><li><p><strong>存储编排</strong></p><p>  Kubernetes 允许你自动挂载你选择的存储系统，例如本地存储、公共云提供商等。</p></li><li><p><strong>自动部署和回滚</strong></p><p>  你可以使用 Kubernetes 描述已部署容器的所需状态， 它可以以受控的速率将实际状态更改为期望状态。 例如，你可以自动化 Kubernetes 来为你的部署创建新容器， 删除现有容器并将它们的所有资源用于新容器。</p></li><li><p><strong>自动完成装箱计算</strong></p><p>  你为 Kubernetes 提供许多节点组成的集群，在这个集群上运行容器化的任务。 你告诉 Kubernetes 每个容器需要多少 CPU 和内存 (RAM)。 Kubernetes 可以将这些容器按实际情况调度到你的节点上，以最佳方式利用你的资源。</p></li><li><p><strong>自我修复</strong></p><p>  Kubernetes 将重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器， 并且在准备好服务之前不将其通告给客户端。</p></li><li><p><strong>密钥与配置管理</strong></p><p>  Kubernetes 允许你存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。 你可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。</p></li></ul><p><img src="https://s3.bmp.ovh/imgs/2023/02/03/30878f6899697c23.png" alt="K8S架构图"></p><h1 id="K8S主要概念"><a href="#K8S主要概念" class="headerlink" title="K8S主要概念"></a>K8S主要概念</h1><p>见该<a href="https://zhuanlan.zhihu.com/p/379270517">知乎文章</a></p><h1 id="kubectl指令安装"><a href="#kubectl指令安装" class="headerlink" title="kubectl指令安装"></a><strong><strong>kubectl指令安装</strong></strong></h1><h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><p><a href="https://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-linux/">在 Linux 系统中安装并设置 kubectl</a></p><h2 id="Macos"><a href="#Macos" class="headerlink" title="Macos"></a>Macos</h2><p><a href="https://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-macos/">在 macOS 系统上安装和设置 kubectl</a></p><h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2><p><a href="https://kubernetes.io/zh-cn/docs/tasks/tools/install-kubectl-windows/">在 Windows 上安装 kubectl</a></p><h1 id="kubectl常用指令"><a href="#kubectl常用指令" class="headerlink" title="kubectl常用指令"></a><strong><strong>kubectl</strong></strong>常用指令</h1><h2 id="get-最常用"><a href="#get-最常用" class="headerlink" title="get(最常用)"></a>get(最常用)</h2><p>使用 get 命令可以获取当前集群中可用的资源列表，包括：</p><ul><li>Namespace</li><li>Pod</li><li>Node</li><li>Deployment</li><li>Service</li><li>ReplicaSet</li></ul><blockquote><p>kubectl get nodes</p></blockquote><p><img src="https://s3.bmp.ovh/imgs/2023/02/03/3f886b6f979f36b5.png" alt="nodes"></p><blockquote><p>kubectl get ns</p></blockquote><p><img src="https://s3.bmp.ovh/imgs/2023/02/03/a5815c32c4f018bc.png" alt="ns"></p><blockquote><p>kubectl  get pod</p></blockquote><p><img src="https://s3.bmp.ovh/imgs/2023/02/03/713bfe82292ff6ee.png" alt="pod"></p><blockquote><p>kubectl -n openmmlab-staging get pod</p></blockquote><p>查看openmmlab-staging命名空间下的pod</p><p><img src="https://s3.bmp.ovh/imgs/2023/02/03/453045410d8f8ca0.png" alt="ns-pod"></p><h2 id="logs-最常用"><a href="#logs-最常用" class="headerlink" title="logs(最常用)"></a>logs(最常用)</h2><p>ogs 命令可以提供 Kubernetes 中 Pod 的更多详细信息。了解这种区别可以帮助开发者更好地对应用程序内部以及 Kubernetes 内部发生的问题，并进行故障排除</p><blockquote><p>kubectl -n openmmlab-staging logs -f –tail 100 aide-be-deploy-86f74f4bb4-gh9js</p></blockquote><p>查看openmmlab-staging命名空间下aide-be-deploy-86f74f4bb4-gh9js容器的日志，显示100行</p><p><img src="https://s3.bmp.ovh/imgs/2023/02/03/e2d248400e7cc4d6.png" alt="logs"></p><h2 id="scale-常用"><a href="#scale-常用" class="headerlink" title="scale(常用)"></a>scale(常用)</h2><blockquote><p>kubectl -n openmmlab-staging scale deploy aide-be-deploy –replicas&#x3D;0</p></blockquote><p>将openmmlab-staging命名空间下aide-be-deploy容器个数设置为0</p><blockquote><p>kubectl -n openmmlab-staging scale deploy aide-be-deploy –replicas&#x3D;1</p></blockquote><p>将openmmlab-staging命名空间下aide-be-deploy容器个数设置为1</p><p>这两个操作&#x3D;&#x3D;重启该服务</p><h2 id="config-常用"><a href="#config-常用" class="headerlink" title="config(常用)"></a>config(常用)</h2><blockquote><p>kubectl config get-contexts</p></blockquote><p><img src="https://s3.bmp.ovh/imgs/2023/02/03/713bfe82292ff6ee.pngg" alt="config"></p><h2 id="create"><a href="#create" class="headerlink" title="create"></a><strong>create</strong></h2><p>可以查询资源后，下一步是创建资源。我们可以用 kubectl 在集群中创建任何类型的资源，包括：</p><ul><li>Service</li><li>Cronjob</li><li>Deployment</li><li>Job</li><li>Namespace（ns）其中，一些资源的创建需要设置配置文件、命名空间以及资源名称。例如，创建命名空间就需要一个额外参数来指定命名空间。</li></ul><figure class="highlight n1ql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs n1ql">$ kubectl <span class="hljs-keyword">create</span> ns hello-there<br><span class="hljs-keyword">namespace</span>/hello-there created<br></code></pre></td></tr></table></figure><h2 id="edit"><a href="#edit" class="headerlink" title="edit"></a><strong>edit</strong></h2><p>当我们创建好资源后，如果需要修改，该怎么办？这时候就需要 kubectl edit 命令了。我们可以用这个命令编辑集群中的任何资源。它会打开默认文本编辑器。如果我们要编辑现有的 cron job，则可以执行：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ kubectl <span class="hljs-built_in">edit</span> cronjob/my-existing-cron<br></code></pre></td></tr></table></figure><h2 id="delete"><a href="#delete" class="headerlink" title="delete"></a><strong>delete</strong></h2><p>学会了以上命令后，下面我们将进行删除操作。刚刚编辑的 cronjob 是两个 cronjobs 之一，现在我们删除整个资源。</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs maxima">$ kubectl <span class="hljs-built_in">delete</span> cronjob my-existing-cron<br>cronjob.<span class="hljs-built_in">batch</span> <span class="hljs-string">&quot;my-existing-cron&quot;</span> deleted<br><span class="hljs-number">12</span><br></code></pre></td></tr></table></figure><p>需要注意的是，如果不知道资源是否有关联信息，最好不要删除。因为删除后无法恢复，只能重新创建。</p><h2 id="apply"><a href="#apply" class="headerlink" title="apply"></a><strong>apply</strong></h2><p>上文提到，某些命令需要配置文件，而 apply 命令可以在集群内调整配置文件应用于资源。虽然也可以通过命令行 standard in (STNIN) 来完成，但 apply 命令更好一些，因为它可以让你知道如何使用集群，以及要应用哪种配置文件。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><br>$ kubectl apply -f commands<span class="hljs-selector-class">.yaml</span><br>serviceaccount/tiller created<br>clusterrolebinding<span class="hljs-selector-class">.rbac</span><span class="hljs-selector-class">.authorization</span><span class="hljs-selector-class">.k8s</span>.io/tiller created<br></code></pre></td></tr></table></figure><h1 id="K8S可视化工具Lens简单介绍"><a href="#K8S可视化工具Lens简单介绍" class="headerlink" title="K8S可视化工具Lens简单介绍"></a>K8S可视化工具Lens简单介绍</h1><p><code>Lens</code> 是一个强大的 kubernetes IDE。可以实时查看 kubernetes 集群状态，比如 Pod实时日志查看、集群Events实时查看、集群故障排查等。有了 Lens，不在需要敲打很长的 kubectl 命令，只要使用鼠标点击几下，非常便捷。</p><p><code>Lens</code> 支持多平台安装，目前支持 <code>Linux</code>、<code>MacOS</code>、<code>Windows</code>。</p><ul><li>用户体验性和可用性非常好</li><li>多集群管理；支持数百个集群</li><li>独立应用程序；无需在集群中安装任何东西</li><li>集群状态实时可视化</li><li>内置 <code>Prometheus</code> 提供资源利用率图表和历史趋势图表</li><li>提供终端访问节点和<a href="https://cloud.tencent.com/product/tke?from=10680">容器</a></li><li>性能经过优化，可应用于大规模集群（已在25k pod的集群进行了测试）</li><li>完全支持 Kubernetes <code>RBAC</code></li></ul><h2 id="界面展示"><a href="#界面展示" class="headerlink" title="界面展示"></a>界面展示</h2><p><img src="https://s3.bmp.ovh/imgs/2023/02/04/8738608a5246c238.png" alt="UI"></p><h2 id="Lens客户端下载"><a href="#Lens客户端下载" class="headerlink" title="Lens客户端下载"></a>Lens客户端下载</h2><p><a href="https://k8slens.dev/">Lens | The Kubernetes IDE</a></p><p><img src="https://s3.bmp.ovh/imgs/2023/02/03/a51e724549ce29ea.png" alt="download"></p><h2 id="激活"><a href="#激活" class="headerlink" title="激活"></a>激活</h2><p>登陆账号后需要用户订阅，可以选择激活免费版然后就可以使用了</p><p><img src="https://s3.bmp.ovh/imgs/2023/02/04/16e677e3c0e1bccb.png" alt="active"></p><p><img src="https://s3.bmp.ovh/imgs/2023/02/04/e24c7ebaa53b189d.png" alt="free"></p><h2 id="添加config配置"><a href="#添加config配置" class="headerlink" title="添加config配置"></a>添加config配置</h2><p>点击<code>add cluster</code>将原本放在<code>/.kube</code>下的config文件copy过来</p><p><img src="https://s3.bmp.ovh/imgs/2023/02/04/9825906f940ffcd4.png" alt="add"></p><p><img src="https://s3.bmp.ovh/imgs/2023/02/04/15a07f14af09a0fc.png" alt="copy config"></p><h2 id="常见操作"><a href="#常见操作" class="headerlink" title="常见操作"></a>常见操作</h2><h3 id="查看nodes"><a href="#查看nodes" class="headerlink" title="查看nodes"></a>查看nodes</h3><p><img src="https://s3.bmp.ovh/imgs/2023/02/04/55976d886c7afa04.png" alt="nodes"></p><h3 id="查看不同namespace下的pods"><a href="#查看不同namespace下的pods" class="headerlink" title="查看不同namespace下的pods"></a>查看不同namespace下的pods</h3><p><img src="https://s3.bmp.ovh/imgs/2023/02/04/99d9254d7ba54c1e.png" alt="pods-ns"></p><h3 id="查看某个pod的日志或者直接连接该pod的shell"><a href="#查看某个pod的日志或者直接连接该pod的shell" class="headerlink" title="查看某个pod的日志或者直接连接该pod的shell"></a>查看某个pod的日志或者直接连接该pod的shell</h3><p><img src="https://s3.bmp.ovh/imgs/2023/02/04/8a1fb43d532b3adb.png" alt="log and shell"></p><h3 id="新建一个terminal终端"><a href="#新建一个terminal终端" class="headerlink" title="新建一个terminal终端"></a>新建一个terminal终端</h3><p><img src="https://s3.bmp.ovh/imgs/2023/02/04/136fc8f53825eba4.png" alt="ternimal"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Lens可以可视化的监控k8s集群的所有数据，可以便捷的查看日志，进行pod的伸缩等，最重要的是界面UI非常好看，好评！</p>]]></content>
    
    
    
    <tags>
      
      <tag>容器</tag>
      
      <tag>中间件</tag>
      
      <tag>云</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>接口开发规范(1)</title>
    <link href="/2023/01/30/%E6%8E%A5%E5%8F%A3%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83-1/"/>
    <url>/2023/01/30/%E6%8E%A5%E5%8F%A3%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83-1/</url>
    
    <content type="html"><![CDATA[<h2 id="文档书写"><a href="#文档书写" class="headerlink" title="文档书写"></a>文档书写</h2><p>开发应该先编写详细接口文档，确定输入输出的命名，类型后再进行开发，避免后续需要修改，同时也可以让需要用到该接口的前端尽早开始开发流程。文档示例如下：</p><blockquote><p>接口名称：XXX<br>调用关系：XXX前端-&gt;XXX后端</p></blockquote><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs text">Schema: HTTP<br>Path: /api/v1/job/getXXX<br>Header:<br>    content-type: application/json;charset=UTF-8<br>Method: POST<br>body:<br>&#123;<br>    &quot;uid&quot;: &quot;STRING&quot;, // 用户id<br>    &quot;jobsNum&quot;: &quot;STRING&quot; // <br>&#125;<br><br>// Response<br>Status Code: 200<br>body:<br>&#123;<br>    &quot;traceId&quot;: &quot;STRING&quot;,<br>    &quot;msgCode&quot;: &quot;STRING&quot;,<br>    &quot;msg&quot;: &quot;STRING&quot;,<br>    &quot;data&quot;: [            <br>        &#123;<br>            &quot;jobId&quot;: &quot;String&quot;, // <br>            &quot;jobName&quot;: &quot;String&quot;, // <br>            &quot;createTime&quot;: &quot;String&quot;, //<br>            &quot;createUserId&quot;: &quot;String&quot;, // <br>            &quot;status&quot;: Integer, // <br>            &quot;clusterId&quot;: &quot;String&quot;, // <br>            &quot;runtime&quot;: &quot;String&quot; // <br>        &#125;<br>    ]<br>&#125;<br></code></pre></td></tr></table></figure><hr><h2 id="接口输入输出"><a href="#接口输入输出" class="headerlink" title="接口输入输出"></a>接口输入输出</h2><h3 id="接口接受的Dto"><a href="#接口接受的Dto" class="headerlink" title="接口接受的Dto"></a>接口接受的Dto</h3><p>每个接口接受的RspDto需要额外编写，尽量不要复用他人的Dto类，因为如果他人的业务逻辑改了，比如改变一个属性的名称，会影响到自己的业务，所以需要尽可能解耦。</p><h3 id="接口返回"><a href="#接口返回" class="headerlink" title="接口返回"></a>接口返回</h3><p>接口返回应该用ReturnBase封装起来，可以自动处理接口调用报错等信息</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@PostMapping(&quot;/getXXXX&quot;)</span><br><span class="hljs-meta">@ApiOperation(&quot;description&quot;)</span><br><span class="hljs-comment">// @OnlyIntranetAccess （内网调用）</span><br><span class="hljs-keyword">public</span> ResponseEntity&lt;ReturnBase&gt; <span class="hljs-title function_">getXXXX</span><span class="hljs-params">()</span>&#123;<br>        <span class="hljs-keyword">return</span> Optional.of(Service.getXXXX())<br>        .map(ret-&gt;<span class="hljs-keyword">new</span> <span class="hljs-title class_">ResponseEntity</span>&lt;&gt;(ret,HttpStatus.OK))<br>        .orElseThrow(()-&gt;<span class="hljs-keyword">new</span> <span class="hljs-title class_">MMException</span>(<span class="hljs-string">&quot;error.job.getXXXX&quot;</span>,ReturnEnum.C_GENERAL_BUSINESS_ERROR.getMsgCode()));<br>        &#125;<br></code></pre></td></tr></table></figure><h3 id="接口返回处理"><a href="#接口返回处理" class="headerlink" title="接口返回处理"></a>接口返回处理</h3><ul><li>处理用ReturnBase封装的接口返回信息时，需要序列化和反序列化，举例如下：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java">String XXXXStr=JsonUtil.jsonObj2Str(XXXXReturn.getData());<br>        List&lt;XXXXRspDto&gt; XXXX=JsonUtil.jsonArrayStr2jsonArray(XXXXStr,XXXXRspDto.class);<br></code></pre></td></tr></table></figure><ul><li>enum枚举类在序列化和反序列化后需要在枚举类上添加@SerializedName注解，否则会变成0。value需要一一对应，如下：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@SerializedName(&quot;0&quot;)</span><br>DELETE(<span class="hljs-number">0</span>,<span class="hljs-string">&quot;删除&quot;</span>,<span class="hljs-string">&quot;Delete&quot;</span>),<br></code></pre></td></tr></table></figure><ul><li>对于返回的信息需要对各项空值进行判断，防止取数据的时候产生报错</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java"><br><span class="hljs-keyword">if</span>(Objects.isNull(getXXXReturn)||<br>        Objects.isNull(getXXXReturn.getData())||<br>        !ReturnEnum.SUCCESS.getMsgCode().equals(getXXXReturn.getMsgCode()))&#123;<br>        log.error(<span class="hljs-string">&quot;get user info by username(&#123;&#125;) from aide-user failed, msg=&#123;&#125;&quot;</span><br>        ,XXX,<br>        Objects.isNull(getUidByNameReturn)?<span class="hljs-string">&quot;null&quot;</span>:getXXXReturn.getMsg());<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>        &#125;<br></code></pre></td></tr></table></figure><hr><h2 id="log等级设置"><a href="#log等级设置" class="headerlink" title="log等级设置"></a>log等级设置</h2><p>用log日志打印的时候，需要判断打印内容长度是否很多，如果内容很多需要使用<code>log.debug</code>而不是<code>log.info</code>。同时在log记录前需要对当前的log<br>level做一个判断，避免不必要的操作</p><hr><h2 id="尽可能规避硬编码"><a href="#尽可能规避硬编码" class="headerlink" title="尽可能规避硬编码"></a>尽可能规避硬编码</h2><p>文本部分尽量避免硬编码，可以采用yml文件配置custom的方式，例如在文本部分尽量避免硬编码，可以采用yml文件配置的方式，例如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">custom:</span><br>  <span class="hljs-attr">bot:</span><br>    <span class="hljs-attr">feishu:</span><br>      <span class="hljs-attr">allSlurmJobOfUserPara:</span><br>        <span class="hljs-attr">defaultJobsNum:</span> <span class="hljs-string">&quot;15&quot;</span><br>        <span class="hljs-attr">nRow:</span> <span class="hljs-string">&quot;-n&quot;</span><br>        <span class="hljs-attr">noJobsReturn:</span> <span class="hljs-string">&quot;没有查询到任务&quot;</span><br>        <span class="hljs-attr">jobsReturn:</span> <span class="hljs-string">&quot;查询到&#123;jobsNum&#125;条任务记录:\n&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> org.openmmlab.platform.aidebot.property;<br><br><span class="hljs-keyword">import</span> cn.hutool.log.LogFactory;<br><span class="hljs-keyword">import</span> lombok.Data;<br><span class="hljs-keyword">import</span> org.springframework.boot.context.properties.ConfigurationProperties;<br><span class="hljs-keyword">import</span> org.springframework.cloud.context.config.annotation.RefreshScope;<br><span class="hljs-keyword">import</span> org.springframework.context.annotation.Configuration;<br><br><span class="hljs-keyword">import</span> java.util.List;<br><br><span class="hljs-meta">@Configuration</span><br><span class="hljs-meta">@ConfigurationProperties(prefix = &quot;custom&quot;)</span><br><span class="hljs-meta">@Data</span><br><span class="hljs-meta">@RefreshScope</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">CustomProperty</span> &#123;<br>    <span class="hljs-keyword">private</span> Bot bot;<br><br>    <span class="hljs-meta">@Data</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Bot</span> &#123;<br>        <span class="hljs-keyword">private</span> Feishu feishu;<br><br>        <span class="hljs-meta">@Data</span><br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Feishu</span> &#123;<br>            <span class="hljs-keyword">private</span> AllSlurmJobOfUserPara allSlurmJobOfUserPara;<br><br>            <span class="hljs-meta">@Data</span><br>            <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AllSlurmJobOfUserPara</span> &#123;<br>                <span class="hljs-keyword">private</span> String defaultJobsNum;<br>                <span class="hljs-keyword">private</span> String nRow;<br>                <span class="hljs-keyword">private</span> String noJobsReturn;<br>                <span class="hljs-keyword">private</span> String jobsReturn;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><hr><h2 id="kafka"><a href="#kafka" class="headerlink" title="kafka"></a>kafka</h2><p>本地运行项目不需要kafka，在项目路径中找到kafka目录，将里面的配置注释掉，否则会报如下错误</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">WARN [AdminClient clientId=adminclient-1] Connection to node -1 (localhost/127.0.0.1:9092) could not<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Java开发</tag>
      
      <tag>Ailab</tag>
      
      <tag>流程规范</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Gitlab 合作开发流程（新人向）</title>
    <link href="/2023/01/06/Gitlab-%E5%90%88%E4%BD%9C%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B%EF%BC%88%E6%96%B0%E4%BA%BA%E5%90%91%EF%BC%89/"/>
    <url>/2023/01/06/Gitlab-%E5%90%88%E4%BD%9C%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B%EF%BC%88%E6%96%B0%E4%BA%BA%E5%90%91%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="后端接口开发流程和规范"><a href="#后端接口开发流程和规范" class="headerlink" title="后端接口开发流程和规范"></a>后端接口开发流程和规范</h1><p>总的来说就是先把项目code clone到本地，然后修改部分配置文件后本地run起来；接着创建新的分支，在新分支上进行功能接口的开发，开发完成后本地用postman进行测试，测试通过后commit，并把进行分支merge，push后发起merge request，给mentor(reviewer) review代码，通过后完成项目开发。如果是接口修改，还需要在接口文档中@相关的前端人员等进行说明。  </p><h2 id="1-代码clone"><a href="#1-代码clone" class="headerlink" title="1.代码clone"></a>1.代码clone</h2><p>首先在gitlab找到代码库，切换develop分支后clone到本地  </p><blockquote><p>git clone xxxx</p></blockquote><h2 id="2-yml文件配置修改"><a href="#2-yml文件配置修改" class="headerlink" title="2.yml文件配置修改"></a>2.yml文件配置修改</h2><p>修改yml文件配置，如spring.profiles.active和bootstrap切换配置文件名，spring.cloud.nacos.discovery.enabled和spring.cloud.nacos.config.enabled设置为false(常见)  </p><h2 id="3-项目启动"><a href="#3-项目启动" class="headerlink" title="3.项目启动"></a>3.项目启动</h2><p>把项目在本地跑起来  </p><h2 id="4-项目开发"><a href="#4-项目开发" class="headerlink" title="4.项目开发"></a>4.项目开发</h2><h3 id="4-1-新建新的分支"><a href="#4-1-新建新的分支" class="headerlink" title="4.1.新建新的分支"></a>4.1.新建新的分支</h3><p>不允许在develop分支上直接开发，需要新建一个分支，分支命名通常为dev_f_xxxx(xxxx是项目编号)<br><strong>ps:项目编号一般可以在飞书等平台上找到</strong></p><h3 id="4-2-切换到新的分支进行开发"><a href="#4-2-切换到新的分支进行开发" class="headerlink" title="4.2.切换到新的分支进行开发"></a>4.2.切换到新的分支进行开发</h3><p>在新的分支上开发  </p><div align=center><img src="https://s3.bmp.ovh/imgs/2023/01/06/bfde56aea5ddbf4d.jpg" style="zoom:100%"></div>  <h3 id="4-3-接口测试"><a href="#4-3-接口测试" class="headerlink" title="4.3.接口测试"></a>4.3.接口测试</h3><p>用postman对开发完毕的接口进行功能测试  </p><h3 id="4-4-代码commit"><a href="#4-4-代码commit" class="headerlink" title="4.4.代码commit"></a>4.4.代码commit</h3><p>将修改后的代码commit，commit内容模板通常为:  </p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs TEXT">项目名称-项目编号-2001 mod/add/del/ref  <br>**(空一行)**  <br>内容，通常是描述做的操作<br></code></pre></td></tr></table></figure><p><strong>ps:yml配置文件通常不允许commit</strong><br><strong>不要在一次commit里提交大量的变更，做到少量多次</strong></p><h3 id="4-5-更新develop"><a href="#4-5-更新develop" class="headerlink" title="4.5.更新develop"></a>4.5.更新develop</h3><p>切换到develop分支，执行git pull操作，将远端最新的代码拉到本地  </p><h3 id="4-6-merge分支"><a href="#4-6-merge分支" class="headerlink" title="4.6.merge分支"></a>4.6.merge分支</h3><p>再切换到dev_f_xxxx分支，将develop分支merge到本分支，有冲突本地解决</p><h3 id="4-7-发起merge-request"><a href="#4-7-发起merge-request" class="headerlink" title="4.7.发起merge request"></a>4.7.发起merge request</h3><p>把自己的分支dev_f_xxx push到远端后，在gitLab上提交merge request把dev_f_xxx合并到develop分支，assign给reviewer  </p><div align=center><img src="https://s3.bmp.ovh/imgs/2023/01/06/54b5b0985021c116.jpg" style="zoom:50%"></div><h2 id="5-流程结束"><a href="#5-流程结束" class="headerlink" title="5.流程结束"></a>5.流程结束</h2>]]></content>
    
    
    
    <tags>
      
      <tag>Java开发</tag>
      
      <tag>Ailab</tag>
      
      <tag>流程规范</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
